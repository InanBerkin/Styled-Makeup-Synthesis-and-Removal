{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/bkkaggle/pytorch-CycleGAN-and-pix2pix/blob/master/pix2pix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VzJFZ1whnGBj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7wNjDKdQy35h"
   },
   "source": [
    "# Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TRm-USlsHgEV"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1896,
     "status": "ok",
     "timestamp": 1609264859321,
     "user": {
      "displayName": "Ege Turan",
      "photoUrl": "",
      "userId": "04174004213434648436"
     },
     "user_tz": -180
    },
    "id": "Pt3igws3eiVp",
    "outputId": "590b579e-f5de-4c6b-b30a-49d32a7e2798"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "os.chdir('/content/drive/My Drive/pytorch-CycleGAN-and-pix2pix-master')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RM6pfTKImtf_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11091,
     "status": "ok",
     "timestamp": 1609264871404,
     "user": {
      "displayName": "Ege Turan",
      "photoUrl": "",
      "userId": "04174004213434648436"
     },
     "user_tz": -180
    },
    "id": "z1EySlOXwwoa",
    "outputId": "7649b582-8f00-4da9-ee06-1a93bbe4e8c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (1.7.0+cu101)\n",
      "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (0.8.1+cu101)\n",
      "Collecting dominate>=2.4.0\n",
      "  Downloading https://files.pythonhosted.org/packages/ef/a8/4354f8122c39e35516a2708746d89db5e339c867abbd8e0179bccee4b7f9/dominate-2.6.0-py2.py3-none-any.whl\n",
      "Collecting visdom>=0.1.8.8\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c9/75/e078f5a2e1df7e0d3044749089fc2823e62d029cc027ed8ae5d71fafcbdc/visdom-0.1.8.9.tar.gz (676kB)\n",
      "\u001b[K     |████████████████████████████████| 686kB 21.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.7.4.3)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (0.16.0)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (0.8)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (1.19.4)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (7.0.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.4.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (2.23.0)\n",
      "Requirement already satisfied: tornado in /usr/local/lib/python3.6/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (5.1.1)\n",
      "Requirement already satisfied: pyzmq in /usr/local/lib/python3.6/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (20.0.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.15.0)\n",
      "Collecting jsonpatch\n",
      "  Downloading https://files.pythonhosted.org/packages/40/d5/6640ac6d1bdd20f44bb6b3c6e6f2f1c525bf0b7595f99c4f38917f995d6b/jsonpatch-1.28-py2.py3-none-any.whl\n",
      "Collecting torchfile\n",
      "  Downloading https://files.pythonhosted.org/packages/91/af/5b305f86f2d218091af657ddb53f984ecbd9518ca9fe8ef4103a007252c9/torchfile-0.1.0.tar.gz\n",
      "Collecting websocket-client\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/5f/f61b420143ed1c8dc69f9eaec5ff1ac36109d52c80de49d66e0c36c3dfdf/websocket_client-0.57.0-py2.py3-none-any.whl (200kB)\n",
      "\u001b[K     |████████████████████████████████| 204kB 54.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (2020.12.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.24.3)\n",
      "Collecting jsonpointer>=1.9\n",
      "  Downloading https://files.pythonhosted.org/packages/18/b0/a80d29577c08eea401659254dfaed87f1af45272899e1812d7e01b679bc5/jsonpointer-2.0-py2.py3-none-any.whl\n",
      "Building wheels for collected packages: visdom, torchfile\n",
      "  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for visdom: filename=visdom-0.1.8.9-cp36-none-any.whl size=655252 sha256=73c897532f73cce53a66eeafc02cdf413d05fc854b9bc4b2be689d1fb2a99bee\n",
      "  Stored in directory: /root/.cache/pip/wheels/70/19/a7/6d589ed967f4dfefd33bc166d081257bd4ed0cb618dccfd62a\n",
      "  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for torchfile: filename=torchfile-0.1.0-cp36-none-any.whl size=5713 sha256=2ef60de3454498b70c94aa8e9dfb42d626a57e3429d938dc225c4f14c6788a1a\n",
      "  Stored in directory: /root/.cache/pip/wheels/b1/c3/d6/9a1cc8f3a99a0fc1124cae20153f36af59a6e683daca0a0814\n",
      "Successfully built visdom torchfile\n",
      "Installing collected packages: dominate, jsonpointer, jsonpatch, torchfile, websocket-client, visdom\n",
      "Successfully installed dominate-2.6.0 jsonpatch-1.28 jsonpointer-2.0 torchfile-0.1.0 visdom-0.1.8.9 websocket-client-0.57.0\n",
      "/content/drive/My Drive/pytorch-CycleGAN-and-pix2pix-master\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8daqlgVhw29P"
   },
   "source": [
    "# Datasets\n",
    "\n",
    "Download one of the official datasets with:\n",
    "\n",
    "-   `bash ./datasets/download_pix2pix_dataset.sh [cityscapes, night2day, edges2handbags, edges2shoes, facades, maps]`\n",
    "\n",
    "Or use your own dataset by creating the appropriate folders and adding in the images. Follow the instructions [here](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/docs/datasets.md#pix2pix-datasets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "executionInfo": {
     "elapsed": 755,
     "status": "ok",
     "timestamp": 1603467663288,
     "user": {
      "displayName": "Ege Turan",
      "photoUrl": "",
      "userId": "04174004213434648436"
     },
     "user_tz": -180
    },
    "id": "vrdOettJxaCc",
    "outputId": "4a9dac30-a3c4-4ed7-9378-236f6d52baec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/download_pix2pix_dataset.sh: line 2: $'\\r': command not found\n",
      "./datasets/download_pix2pix_dataset.sh: line 23: syntax error: unexpected end of file\n"
     ]
    }
   ],
   "source": [
    "!bash ./datasets/download_pix2pix_dataset.sh night2day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gdUz4116xhpm"
   },
   "source": [
    "# Pretrained models\n",
    "\n",
    "Download one of the official pretrained models with:\n",
    "\n",
    "-   `bash ./scripts/download_pix2pix_model.sh [edges2shoes, sat2map, map2sat, facades_label2photo, and day2night]`\n",
    "\n",
    "Or add your own pretrained model to `./checkpoints/{NAME}_pretrained/latest_net_G.pt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "executionInfo": {
     "elapsed": 8939,
     "status": "ok",
     "timestamp": 1603467311539,
     "user": {
      "displayName": "Ege Turan",
      "photoUrl": "",
      "userId": "04174004213434648436"
     },
     "user_tz": -180
    },
    "id": "GC2DEP4M0OsS",
    "outputId": "34e497dc-0279-4f9d-daf0-2da0991c4bec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: available models are edges2shoes, sat2map, map2sat, facades_label2photo, and day2night\n",
      "Specified [day2night]\n",
      "WARNING: timestamping does nothing in combination with -O. See the manual\n",
      "for details.\n",
      "\n",
      "--2020-10-23 15:35:07--  http://efrosgans.eecs.berkeley.edu/pix2pix/models-pytorch/day2night.pth\n",
      "Resolving efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)... 128.32.189.73\n",
      "Connecting to efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)|128.32.189.73|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 217710797 (208M)\n",
      "Saving to: ‘./checkpoints/day2night_pretrained/latest_net_G.pth’\n",
      "\n",
      "./checkpoints/day2n 100%[===================>] 207.62M  55.5MB/s    in 4.1s    \n",
      "\n",
      "2020-10-23 15:35:11 (51.0 MB/s) - ‘./checkpoints/day2night_pretrained/latest_net_G.pth’ saved [217710797/217710797]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!bash ./scripts/download_pix2pix_model.sh day2night"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yFw1kDQBx3LN"
   },
   "source": [
    "# Training\n",
    "\n",
    "-   `python train.py --dataroot ./datasets/facades --name facades_pix2pix --model pix2pix --direction BtoA`\n",
    "\n",
    "Change the `--dataroot` and `--name` to your own dataset's path and model's name. Use `--gpu_ids 0,1,..` to train on multiple GPUs and `--batch_size` to change the batch size. Add `--direction BtoA` if you want to train a model to transfrom from class B to A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0sp7TCT2x9dB",
    "outputId": "75e100f9-5c01-45c1-aaa3-044c7eee874d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for scripts.\n",
      "It's Alive!\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/visdom/server.py\", line 1922, in <module>\n",
      "    download_scripts_and_run()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/visdom/server.py\", line 1918, in download_scripts_and_run\n",
      "    main()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/visdom/server.py\", line 1913, in main\n",
      "    use_frontend_client_polling=FLAGS.use_frontend_client_polling)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/visdom/server.py\", line 1791, in start_server\n",
      "    app.listen(port, max_buffer_size=1024 ** 3)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tornado/web.py\", line 2042, in listen\n",
      "    server.listen(port, address)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tornado/tcpserver.py\", line 143, in listen\n",
      "    sockets = bind_sockets(port, address=address)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tornado/netutil.py\", line 168, in bind_sockets\n",
      "    sock.bind(sockaddr)\n",
      "OSError: [Errno 98] Address already in use\n",
      "----------------- Options ---------------\n",
      "               batch_size: 1                             \n",
      "                    beta1: 0.5                           \n",
      "          checkpoints_dir: /content/drive/My Drive/pytorch-CycleGAN-and-pix2pix-master/checkpoints\n",
      "           continue_train: False                         \n",
      "                crop_size: 256                           \n",
      "                 dataroot: /content/drive/My Drive/pytorch-CycleGAN-and-pix2pix-master/datasets/makeup\t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: BtoA                          \t[default: AtoB]\n",
      "              display_env: main                          \n",
      "             display_freq: 400                           \n",
      "               display_id: 1                             \n",
      "            display_ncols: 4                             \n",
      "             display_port: 8097                          \n",
      "           display_server: http://localhost              \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 1                             \n",
      "                 gan_mode: vanilla                       \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: True                          \t[default: None]\n",
      "                lambda_L1: 100.0                         \n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 286                           \n",
      "                       lr: 0.0002                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: cycle_gan]\n",
      "                 n_epochs: 100                           \n",
      "           n_epochs_decay: 100                           \n",
      "               n_layers_D: 3                             \n",
      "                     name: makeup                        \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_256                      \n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                  no_html: False                         \n",
      "                     norm: batch                         \n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: train                         \n",
      "                pool_size: 0                             \n",
      "               preprocess: resize_and_crop               \n",
      "               print_freq: 100                           \n",
      "             save_by_iter: False                         \n",
      "          save_epoch_freq: 5                             \n",
      "         save_latest_freq: 5000                          \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "         update_html_freq: 1000                          \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "The number of training images = 767\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 54.414 M\n",
      "[Network D] Total number of parameters : 2.769 M\n",
      "-----------------------------------------------\n",
      "Setting up a new session...\n",
      "create web directory /content/drive/My Drive/pytorch-CycleGAN-and-pix2pix-master/checkpoints/makeup/web...\n",
      "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 1, iters: 100, time: 0.094, data: 0.459) G_GAN: 0.874 G_L1: 20.153 D_real: 0.599 D_fake: 0.696 \n",
      "(epoch: 1, iters: 200, time: 0.100, data: 0.003) G_GAN: 1.113 G_L1: 14.013 D_real: 0.507 D_fake: 0.528 \n",
      "(epoch: 1, iters: 300, time: 0.094, data: 0.002) G_GAN: 0.779 G_L1: 13.654 D_real: 1.212 D_fake: 0.574 \n",
      "(epoch: 1, iters: 400, time: 0.298, data: 0.000) G_GAN: 2.176 G_L1: 19.266 D_real: 0.245 D_fake: 0.212 \n",
      "(epoch: 1, iters: 500, time: 0.096, data: 0.000) G_GAN: 1.900 G_L1: 23.969 D_real: 0.227 D_fake: 0.270 \n",
      "(epoch: 1, iters: 600, time: 0.094, data: 0.001) G_GAN: 1.743 G_L1: 23.031 D_real: 0.062 D_fake: 0.673 \n",
      "(epoch: 1, iters: 700, time: 0.106, data: 0.002) G_GAN: 2.223 G_L1: 19.094 D_real: 0.353 D_fake: 0.174 \n",
      "End of epoch 1 / 200 \t Time Taken: 48 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 2, iters: 33, time: 0.319, data: 0.000) G_GAN: 1.370 G_L1: 19.524 D_real: 1.331 D_fake: 0.230 \n",
      "(epoch: 2, iters: 133, time: 0.105, data: 0.001) G_GAN: 1.313 G_L1: 15.041 D_real: 0.689 D_fake: 0.106 \n",
      "(epoch: 2, iters: 233, time: 0.105, data: 0.005) G_GAN: 1.886 G_L1: 28.902 D_real: 0.010 D_fake: 0.940 \n",
      "(epoch: 2, iters: 333, time: 0.103, data: 0.001) G_GAN: 0.530 G_L1: 18.246 D_real: 1.954 D_fake: 0.714 \n",
      "(epoch: 2, iters: 433, time: 0.205, data: 0.002) G_GAN: 1.981 G_L1: 21.809 D_real: 0.027 D_fake: 0.231 \n",
      "(epoch: 2, iters: 533, time: 0.106, data: 0.001) G_GAN: 0.798 G_L1: 13.011 D_real: 1.048 D_fake: 0.183 \n",
      "(epoch: 2, iters: 633, time: 0.103, data: 0.001) G_GAN: 1.596 G_L1: 35.096 D_real: 0.035 D_fake: 0.319 \n",
      "(epoch: 2, iters: 733, time: 0.106, data: 0.001) G_GAN: 1.917 G_L1: 18.214 D_real: 0.148 D_fake: 0.179 \n",
      "End of epoch 2 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 3, iters: 66, time: 0.315, data: 0.001) G_GAN: 1.019 G_L1: 14.583 D_real: 0.861 D_fake: 0.242 \n",
      "(epoch: 3, iters: 166, time: 0.099, data: 0.001) G_GAN: 1.125 G_L1: 16.332 D_real: 1.103 D_fake: 0.098 \n",
      "(epoch: 3, iters: 266, time: 0.105, data: 0.002) G_GAN: 0.992 G_L1: 11.014 D_real: 1.875 D_fake: 0.191 \n",
      "(epoch: 3, iters: 366, time: 0.104, data: 0.002) G_GAN: 2.068 G_L1: 19.203 D_real: 0.692 D_fake: 0.174 \n",
      "(epoch: 3, iters: 466, time: 0.309, data: 0.001) G_GAN: 2.507 G_L1: 28.391 D_real: 0.006 D_fake: 0.223 \n",
      "(epoch: 3, iters: 566, time: 0.103, data: 0.002) G_GAN: 1.262 G_L1: 14.890 D_real: 0.484 D_fake: 0.215 \n",
      "(epoch: 3, iters: 666, time: 0.104, data: 0.002) G_GAN: 1.481 G_L1: 13.427 D_real: 0.615 D_fake: 0.149 \n",
      "(epoch: 3, iters: 766, time: 0.105, data: 0.001) G_GAN: 2.116 G_L1: 23.437 D_real: 0.012 D_fake: 0.409 \n",
      "End of epoch 3 / 200 \t Time Taken: 48 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 4, iters: 99, time: 0.314, data: 0.001) G_GAN: 0.885 G_L1: 12.634 D_real: 0.923 D_fake: 0.705 \n",
      "(epoch: 4, iters: 199, time: 0.102, data: 0.002) G_GAN: 2.086 G_L1: 26.637 D_real: 0.002 D_fake: 0.568 \n",
      "(epoch: 4, iters: 299, time: 0.106, data: 0.002) G_GAN: 1.911 G_L1: 15.174 D_real: 2.207 D_fake: 0.123 \n",
      "(epoch: 4, iters: 399, time: 0.105, data: 0.002) G_GAN: 2.353 G_L1: 21.316 D_real: 0.159 D_fake: 0.092 \n",
      "(epoch: 4, iters: 499, time: 0.207, data: 0.001) G_GAN: 2.318 G_L1: 23.057 D_real: 0.054 D_fake: 0.096 \n",
      "(epoch: 4, iters: 599, time: 0.104, data: 0.002) G_GAN: 1.812 G_L1: 18.832 D_real: 0.079 D_fake: 1.448 \n",
      "(epoch: 4, iters: 699, time: 0.092, data: 0.001) G_GAN: 1.889 G_L1: 30.197 D_real: 0.003 D_fake: 0.303 \n",
      "End of epoch 4 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 5, iters: 32, time: 0.106, data: 0.001) G_GAN: 2.645 G_L1: 21.649 D_real: 0.313 D_fake: 0.078 \n",
      "(epoch: 5, iters: 132, time: 0.330, data: 0.001) G_GAN: 0.895 G_L1: 11.190 D_real: 0.978 D_fake: 0.235 \n",
      "(epoch: 5, iters: 232, time: 0.102, data: 0.001) G_GAN: 1.989 G_L1: 15.725 D_real: 0.482 D_fake: 0.188 \n",
      "(epoch: 5, iters: 332, time: 0.104, data: 0.002) G_GAN: 2.138 G_L1: 25.979 D_real: 0.043 D_fake: 0.162 \n",
      "(epoch: 5, iters: 432, time: 0.102, data: 0.002) G_GAN: 2.374 G_L1: 16.120 D_real: 0.044 D_fake: 0.162 \n",
      "(epoch: 5, iters: 532, time: 0.204, data: 0.002) G_GAN: 1.682 G_L1: 17.813 D_real: 0.667 D_fake: 0.294 \n",
      "(epoch: 5, iters: 632, time: 0.102, data: 0.002) G_GAN: 2.044 G_L1: 25.721 D_real: 0.069 D_fake: 0.206 \n",
      "(epoch: 5, iters: 732, time: 0.101, data: 0.002) G_GAN: 1.493 G_L1: 22.523 D_real: 0.166 D_fake: 0.690 \n",
      "saving the model at the end of epoch 5, iters 3835\n",
      "End of epoch 5 / 200 \t Time Taken: 51 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 6, iters: 65, time: 0.099, data: 0.002) G_GAN: 1.208 G_L1: 8.923 D_real: 0.436 D_fake: 0.351 \n",
      "(epoch: 6, iters: 165, time: 0.322, data: 0.001) G_GAN: 1.444 G_L1: 16.829 D_real: 0.562 D_fake: 0.927 \n",
      "(epoch: 6, iters: 265, time: 0.100, data: 0.002) G_GAN: 1.547 G_L1: 11.104 D_real: 0.631 D_fake: 0.179 \n",
      "(epoch: 6, iters: 365, time: 0.106, data: 0.001) G_GAN: 1.713 G_L1: 20.782 D_real: 1.684 D_fake: 0.087 \n",
      "(epoch: 6, iters: 465, time: 0.106, data: 0.001) G_GAN: 2.430 G_L1: 18.633 D_real: 0.166 D_fake: 0.182 \n",
      "(epoch: 6, iters: 565, time: 0.204, data: 0.002) G_GAN: 2.176 G_L1: 21.245 D_real: 0.086 D_fake: 0.143 \n",
      "(epoch: 6, iters: 665, time: 0.105, data: 0.002) G_GAN: 2.879 G_L1: 21.873 D_real: 0.005 D_fake: 0.217 \n",
      "(epoch: 6, iters: 765, time: 0.104, data: 0.002) G_GAN: 2.752 G_L1: 22.116 D_real: 0.002 D_fake: 0.113 \n",
      "End of epoch 6 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 7, iters: 98, time: 0.104, data: 0.002) G_GAN: 1.922 G_L1: 19.726 D_real: 1.104 D_fake: 0.045 \n",
      "(epoch: 7, iters: 198, time: 0.334, data: 0.001) G_GAN: 2.523 G_L1: 13.267 D_real: 0.174 D_fake: 0.145 \n",
      "(epoch: 7, iters: 298, time: 0.105, data: 0.001) G_GAN: 1.199 G_L1: 14.048 D_real: 0.423 D_fake: 0.457 \n",
      "(epoch: 7, iters: 398, time: 0.106, data: 0.001) G_GAN: 1.404 G_L1: 21.047 D_real: 0.031 D_fake: 0.508 \n",
      "saving the latest model (epoch 7, total_iters 5000)\n",
      "(epoch: 7, iters: 498, time: 0.106, data: 0.002) G_GAN: 2.028 G_L1: 21.996 D_real: 0.028 D_fake: 0.438 \n",
      "(epoch: 7, iters: 598, time: 0.211, data: 0.001) G_GAN: 1.898 G_L1: 21.000 D_real: 0.207 D_fake: 0.257 \n",
      "(epoch: 7, iters: 698, time: 0.105, data: 0.002) G_GAN: 2.154 G_L1: 31.335 D_real: 0.355 D_fake: 0.323 \n",
      "End of epoch 7 / 200 \t Time Taken: 50 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 8, iters: 31, time: 0.107, data: 0.002) G_GAN: 2.866 G_L1: 21.171 D_real: 0.029 D_fake: 0.078 \n",
      "(epoch: 8, iters: 131, time: 0.106, data: 0.001) G_GAN: 1.295 G_L1: 16.456 D_real: 0.097 D_fake: 0.447 \n",
      "(epoch: 8, iters: 231, time: 0.341, data: 0.002) G_GAN: 1.903 G_L1: 16.845 D_real: 0.388 D_fake: 0.195 \n",
      "(epoch: 8, iters: 331, time: 0.104, data: 0.002) G_GAN: 0.668 G_L1: 11.398 D_real: 0.727 D_fake: 0.345 \n",
      "(epoch: 8, iters: 431, time: 0.105, data: 0.002) G_GAN: 3.142 G_L1: 19.158 D_real: 0.003 D_fake: 0.095 \n",
      "(epoch: 8, iters: 531, time: 0.105, data: 0.001) G_GAN: 2.491 G_L1: 29.453 D_real: 0.200 D_fake: 0.100 \n",
      "(epoch: 8, iters: 631, time: 0.346, data: 0.001) G_GAN: 2.787 G_L1: 25.092 D_real: 0.003 D_fake: 0.093 \n",
      "(epoch: 8, iters: 731, time: 0.104, data: 0.002) G_GAN: 1.882 G_L1: 11.028 D_real: 1.271 D_fake: 0.045 \n",
      "End of epoch 8 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 9, iters: 64, time: 0.105, data: 0.001) G_GAN: 1.068 G_L1: 18.923 D_real: 0.640 D_fake: 0.173 \n",
      "(epoch: 9, iters: 164, time: 0.104, data: 0.001) G_GAN: 1.986 G_L1: 10.023 D_real: 1.390 D_fake: 0.056 \n",
      "(epoch: 9, iters: 264, time: 0.333, data: 0.001) G_GAN: 0.850 G_L1: 12.646 D_real: 0.708 D_fake: 0.202 \n",
      "(epoch: 9, iters: 364, time: 0.103, data: 0.002) G_GAN: 2.052 G_L1: 9.883 D_real: 0.014 D_fake: 2.064 \n",
      "(epoch: 9, iters: 464, time: 0.104, data: 0.001) G_GAN: 2.778 G_L1: 16.015 D_real: 0.032 D_fake: 0.065 \n",
      "(epoch: 9, iters: 564, time: 0.103, data: 0.002) G_GAN: 1.119 G_L1: 18.574 D_real: 0.559 D_fake: 0.743 \n",
      "(epoch: 9, iters: 664, time: 0.198, data: 0.001) G_GAN: 1.918 G_L1: 10.722 D_real: 0.497 D_fake: 0.110 \n",
      "(epoch: 9, iters: 764, time: 0.106, data: 0.001) G_GAN: 1.594 G_L1: 11.916 D_real: 1.353 D_fake: 0.047 \n",
      "End of epoch 9 / 200 \t Time Taken: 48 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 10, iters: 97, time: 0.105, data: 0.002) G_GAN: 2.457 G_L1: 20.186 D_real: 0.001 D_fake: 0.117 \n",
      "(epoch: 10, iters: 197, time: 0.105, data: 0.001) G_GAN: 1.054 G_L1: 19.374 D_real: 0.802 D_fake: 0.328 \n",
      "(epoch: 10, iters: 297, time: 0.367, data: 0.002) G_GAN: 1.004 G_L1: 13.524 D_real: 0.855 D_fake: 0.434 \n",
      "(epoch: 10, iters: 397, time: 0.101, data: 0.001) G_GAN: 1.571 G_L1: 16.444 D_real: 0.035 D_fake: 0.252 \n",
      "(epoch: 10, iters: 497, time: 0.105, data: 0.001) G_GAN: 1.222 G_L1: 18.167 D_real: 0.003 D_fake: 0.996 \n",
      "(epoch: 10, iters: 597, time: 0.105, data: 0.001) G_GAN: 2.066 G_L1: 11.620 D_real: 0.373 D_fake: 0.077 \n",
      "(epoch: 10, iters: 697, time: 0.212, data: 0.002) G_GAN: 1.963 G_L1: 24.820 D_real: 0.002 D_fake: 0.413 \n",
      "saving the model at the end of epoch 10, iters 7670\n",
      "End of epoch 10 / 200 \t Time Taken: 51 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 11, iters: 30, time: 0.105, data: 0.001) G_GAN: 0.602 G_L1: 14.544 D_real: 1.497 D_fake: 0.267 \n",
      "(epoch: 11, iters: 130, time: 0.092, data: 0.001) G_GAN: 1.658 G_L1: 20.372 D_real: 0.038 D_fake: 0.213 \n",
      "(epoch: 11, iters: 230, time: 0.098, data: 0.002) G_GAN: 1.228 G_L1: 16.746 D_real: 1.604 D_fake: 0.445 \n",
      "(epoch: 11, iters: 330, time: 0.336, data: 0.001) G_GAN: 1.500 G_L1: 25.697 D_real: 0.009 D_fake: 1.014 \n",
      "(epoch: 11, iters: 430, time: 0.103, data: 0.002) G_GAN: 2.574 G_L1: 13.733 D_real: 0.190 D_fake: 0.128 \n",
      "(epoch: 11, iters: 530, time: 0.104, data: 0.001) G_GAN: 1.595 G_L1: 21.279 D_real: 0.066 D_fake: 0.279 \n",
      "(epoch: 11, iters: 630, time: 0.104, data: 0.002) G_GAN: 1.614 G_L1: 10.967 D_real: 0.958 D_fake: 0.088 \n",
      "(epoch: 11, iters: 730, time: 0.213, data: 0.002) G_GAN: 2.081 G_L1: 15.378 D_real: 0.494 D_fake: 0.071 \n",
      "End of epoch 11 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 12, iters: 63, time: 0.104, data: 0.002) G_GAN: 2.014 G_L1: 10.966 D_real: 0.296 D_fake: 0.089 \n",
      "(epoch: 12, iters: 163, time: 0.105, data: 0.001) G_GAN: 1.306 G_L1: 11.692 D_real: 1.785 D_fake: 0.651 \n",
      "(epoch: 12, iters: 263, time: 0.104, data: 0.002) G_GAN: 1.589 G_L1: 21.776 D_real: 0.075 D_fake: 0.720 \n",
      "(epoch: 12, iters: 363, time: 0.374, data: 0.002) G_GAN: 1.574 G_L1: 37.711 D_real: 0.001 D_fake: 0.523 \n",
      "(epoch: 12, iters: 463, time: 0.104, data: 0.001) G_GAN: 1.591 G_L1: 10.575 D_real: 0.747 D_fake: 0.093 \n",
      "(epoch: 12, iters: 563, time: 0.100, data: 0.002) G_GAN: 1.934 G_L1: 24.458 D_real: 0.012 D_fake: 0.575 \n",
      "(epoch: 12, iters: 663, time: 0.104, data: 0.002) G_GAN: 1.107 G_L1: 14.286 D_real: 0.316 D_fake: 0.455 \n",
      "(epoch: 12, iters: 763, time: 0.210, data: 0.001) G_GAN: 1.097 G_L1: 21.585 D_real: 1.737 D_fake: 0.782 \n",
      "End of epoch 12 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 13, iters: 96, time: 0.106, data: 0.001) G_GAN: 1.786 G_L1: 23.138 D_real: 0.464 D_fake: 0.266 \n",
      "(epoch: 13, iters: 196, time: 0.105, data: 0.001) G_GAN: 2.131 G_L1: 10.989 D_real: 0.168 D_fake: 0.864 \n",
      "(epoch: 13, iters: 296, time: 0.104, data: 0.001) G_GAN: 0.753 G_L1: 10.550 D_real: 0.912 D_fake: 0.512 \n",
      "(epoch: 13, iters: 396, time: 0.376, data: 0.001) G_GAN: 2.516 G_L1: 12.039 D_real: 0.764 D_fake: 0.078 \n",
      "(epoch: 13, iters: 496, time: 0.105, data: 0.002) G_GAN: 1.554 G_L1: 22.452 D_real: 0.415 D_fake: 0.239 \n",
      "(epoch: 13, iters: 596, time: 0.104, data: 0.002) G_GAN: 1.887 G_L1: 18.465 D_real: 0.395 D_fake: 0.143 \n",
      "(epoch: 13, iters: 696, time: 0.101, data: 0.001) G_GAN: 2.134 G_L1: 26.453 D_real: 0.114 D_fake: 0.344 \n",
      "End of epoch 13 / 200 \t Time Taken: 48 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 14, iters: 29, time: 0.346, data: 0.001) G_GAN: 3.214 G_L1: 31.270 D_real: 0.241 D_fake: 0.071 \n",
      "saving the latest model (epoch 14, total_iters 10000)\n",
      "(epoch: 14, iters: 129, time: 0.104, data: 0.002) G_GAN: 0.996 G_L1: 10.845 D_real: 0.661 D_fake: 0.285 \n",
      "(epoch: 14, iters: 229, time: 0.105, data: 0.002) G_GAN: 1.636 G_L1: 17.825 D_real: 0.043 D_fake: 0.508 \n",
      "(epoch: 14, iters: 329, time: 0.106, data: 0.002) G_GAN: 1.791 G_L1: 16.906 D_real: 0.152 D_fake: 1.091 \n",
      "(epoch: 14, iters: 429, time: 0.208, data: 0.001) G_GAN: 1.006 G_L1: 13.945 D_real: 1.706 D_fake: 0.074 \n",
      "(epoch: 14, iters: 529, time: 0.104, data: 0.001) G_GAN: 1.307 G_L1: 10.983 D_real: 1.771 D_fake: 0.206 \n",
      "(epoch: 14, iters: 629, time: 0.104, data: 0.002) G_GAN: 0.937 G_L1: 9.921 D_real: 1.105 D_fake: 0.276 \n",
      "(epoch: 14, iters: 729, time: 0.104, data: 0.001) G_GAN: 1.779 G_L1: 14.608 D_real: 0.068 D_fake: 0.801 \n",
      "End of epoch 14 / 200 \t Time Taken: 50 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 15, iters: 62, time: 0.346, data: 0.001) G_GAN: 0.696 G_L1: 7.711 D_real: 0.843 D_fake: 0.961 \n",
      "(epoch: 15, iters: 162, time: 0.105, data: 0.002) G_GAN: 2.110 G_L1: 26.349 D_real: 0.125 D_fake: 0.209 \n",
      "(epoch: 15, iters: 262, time: 0.098, data: 0.002) G_GAN: 1.413 G_L1: 15.707 D_real: 0.006 D_fake: 1.033 \n",
      "(epoch: 15, iters: 362, time: 0.104, data: 0.001) G_GAN: 2.750 G_L1: 23.446 D_real: 0.003 D_fake: 0.082 \n",
      "(epoch: 15, iters: 462, time: 0.220, data: 0.001) G_GAN: 2.701 G_L1: 13.611 D_real: 0.123 D_fake: 0.172 \n",
      "(epoch: 15, iters: 562, time: 0.105, data: 0.002) G_GAN: 3.035 G_L1: 8.635 D_real: 0.017 D_fake: 0.114 \n",
      "(epoch: 15, iters: 662, time: 0.104, data: 0.001) G_GAN: 1.652 G_L1: 16.042 D_real: 0.413 D_fake: 0.568 \n",
      "(epoch: 15, iters: 762, time: 0.104, data: 0.001) G_GAN: 1.118 G_L1: 22.726 D_real: 0.123 D_fake: 0.578 \n",
      "saving the model at the end of epoch 15, iters 11505\n",
      "End of epoch 15 / 200 \t Time Taken: 51 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 16, iters: 95, time: 0.433, data: 0.001) G_GAN: 2.841 G_L1: 6.716 D_real: 0.013 D_fake: 0.287 \n",
      "(epoch: 16, iters: 195, time: 0.097, data: 0.002) G_GAN: 1.521 G_L1: 18.296 D_real: 0.065 D_fake: 1.959 \n",
      "(epoch: 16, iters: 295, time: 0.105, data: 0.003) G_GAN: 1.782 G_L1: 17.917 D_real: 0.153 D_fake: 0.455 \n",
      "(epoch: 16, iters: 395, time: 0.104, data: 0.001) G_GAN: 1.451 G_L1: 10.674 D_real: 1.066 D_fake: 0.191 \n",
      "(epoch: 16, iters: 495, time: 0.356, data: 0.001) G_GAN: 2.974 G_L1: 12.893 D_real: 1.231 D_fake: 0.037 \n",
      "(epoch: 16, iters: 595, time: 0.106, data: 0.001) G_GAN: 3.211 G_L1: 7.697 D_real: 0.033 D_fake: 0.031 \n",
      "(epoch: 16, iters: 695, time: 0.103, data: 0.001) G_GAN: 1.116 G_L1: 14.104 D_real: 0.539 D_fake: 0.140 \n",
      "End of epoch 16 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 17, iters: 28, time: 0.103, data: 0.002) G_GAN: 1.427 G_L1: 18.904 D_real: 0.071 D_fake: 1.320 \n",
      "(epoch: 17, iters: 128, time: 0.379, data: 0.001) G_GAN: 1.668 G_L1: 20.624 D_real: 0.107 D_fake: 0.456 \n",
      "(epoch: 17, iters: 228, time: 0.099, data: 0.002) G_GAN: 0.739 G_L1: 9.026 D_real: 0.929 D_fake: 0.551 \n",
      "(epoch: 17, iters: 328, time: 0.105, data: 0.002) G_GAN: 1.848 G_L1: 14.330 D_real: 0.241 D_fake: 0.648 \n",
      "(epoch: 17, iters: 428, time: 0.105, data: 0.001) G_GAN: 1.440 G_L1: 23.611 D_real: 0.146 D_fake: 0.294 \n",
      "(epoch: 17, iters: 528, time: 0.215, data: 0.001) G_GAN: 1.525 G_L1: 11.415 D_real: 0.380 D_fake: 0.220 \n",
      "(epoch: 17, iters: 628, time: 0.099, data: 0.001) G_GAN: 3.874 G_L1: 15.086 D_real: 0.000 D_fake: 0.741 \n",
      "(epoch: 17, iters: 728, time: 0.105, data: 0.001) G_GAN: 3.332 G_L1: 13.037 D_real: 0.047 D_fake: 1.308 \n",
      "End of epoch 17 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 18, iters: 61, time: 0.105, data: 0.002) G_GAN: 1.874 G_L1: 21.089 D_real: 0.001 D_fake: 0.312 \n",
      "(epoch: 18, iters: 161, time: 0.368, data: 0.001) G_GAN: 1.733 G_L1: 18.388 D_real: 0.172 D_fake: 1.050 \n",
      "(epoch: 18, iters: 261, time: 0.106, data: 0.002) G_GAN: 2.234 G_L1: 14.068 D_real: 3.325 D_fake: 0.038 \n",
      "(epoch: 18, iters: 361, time: 0.104, data: 0.001) G_GAN: 1.955 G_L1: 18.930 D_real: 1.221 D_fake: 0.071 \n",
      "(epoch: 18, iters: 461, time: 0.105, data: 0.001) G_GAN: 1.687 G_L1: 17.266 D_real: 0.079 D_fake: 1.162 \n",
      "(epoch: 18, iters: 561, time: 0.206, data: 0.002) G_GAN: 1.392 G_L1: 13.165 D_real: 1.935 D_fake: 0.118 \n",
      "(epoch: 18, iters: 661, time: 0.105, data: 0.001) G_GAN: 2.670 G_L1: 9.156 D_real: 0.493 D_fake: 0.054 \n",
      "(epoch: 18, iters: 761, time: 0.105, data: 0.001) G_GAN: 1.257 G_L1: 15.622 D_real: 0.027 D_fake: 0.486 \n",
      "End of epoch 18 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 19, iters: 94, time: 0.107, data: 0.001) G_GAN: 2.340 G_L1: 20.804 D_real: 0.043 D_fake: 0.153 \n",
      "(epoch: 19, iters: 194, time: 0.398, data: 0.001) G_GAN: 3.645 G_L1: 19.022 D_real: 0.086 D_fake: 0.038 \n",
      "(epoch: 19, iters: 294, time: 0.106, data: 0.002) G_GAN: 4.003 G_L1: 10.502 D_real: 0.031 D_fake: 1.244 \n",
      "(epoch: 19, iters: 394, time: 0.105, data: 0.002) G_GAN: 0.816 G_L1: 15.466 D_real: 0.445 D_fake: 0.437 \n",
      "(epoch: 19, iters: 494, time: 0.100, data: 0.001) G_GAN: 1.012 G_L1: 13.345 D_real: 0.057 D_fake: 1.053 \n",
      "(epoch: 19, iters: 594, time: 0.213, data: 0.001) G_GAN: 2.314 G_L1: 14.221 D_real: 0.072 D_fake: 0.137 \n",
      "(epoch: 19, iters: 694, time: 0.101, data: 0.001) G_GAN: 1.277 G_L1: 8.766 D_real: 1.595 D_fake: 0.084 \n",
      "End of epoch 19 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 20, iters: 27, time: 0.104, data: 0.002) G_GAN: 2.410 G_L1: 7.681 D_real: 0.003 D_fake: 0.192 \n",
      "(epoch: 20, iters: 127, time: 0.106, data: 0.001) G_GAN: 4.057 G_L1: 12.058 D_real: 0.244 D_fake: 0.027 \n",
      "(epoch: 20, iters: 227, time: 0.367, data: 0.002) G_GAN: 1.260 G_L1: 16.267 D_real: 0.564 D_fake: 0.202 \n",
      "(epoch: 20, iters: 327, time: 0.105, data: 0.001) G_GAN: 2.545 G_L1: 10.629 D_real: 0.001 D_fake: 0.251 \n",
      "(epoch: 20, iters: 427, time: 0.104, data: 0.001) G_GAN: 3.006 G_L1: 11.258 D_real: 0.254 D_fake: 1.141 \n",
      "saving the latest model (epoch 20, total_iters 15000)\n",
      "(epoch: 20, iters: 527, time: 0.105, data: 0.001) G_GAN: 2.286 G_L1: 17.949 D_real: 0.630 D_fake: 0.081 \n",
      "(epoch: 20, iters: 627, time: 0.216, data: 0.002) G_GAN: 1.670 G_L1: 12.821 D_real: 0.768 D_fake: 0.195 \n",
      "(epoch: 20, iters: 727, time: 0.105, data: 0.002) G_GAN: 1.666 G_L1: 15.024 D_real: 0.244 D_fake: 0.341 \n",
      "saving the model at the end of epoch 20, iters 15340\n",
      "End of epoch 20 / 200 \t Time Taken: 52 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 21, iters: 60, time: 0.104, data: 0.001) G_GAN: 0.517 G_L1: 9.121 D_real: 0.954 D_fake: 0.239 \n",
      "(epoch: 21, iters: 160, time: 0.100, data: 0.001) G_GAN: 2.066 G_L1: 9.371 D_real: 1.383 D_fake: 0.052 \n",
      "(epoch: 21, iters: 260, time: 0.380, data: 0.002) G_GAN: 4.466 G_L1: 7.532 D_real: 0.027 D_fake: 1.771 \n",
      "(epoch: 21, iters: 360, time: 0.106, data: 0.002) G_GAN: 1.808 G_L1: 11.388 D_real: 1.760 D_fake: 0.049 \n",
      "(epoch: 21, iters: 460, time: 0.106, data: 0.001) G_GAN: 2.256 G_L1: 23.331 D_real: 0.017 D_fake: 0.621 \n",
      "(epoch: 21, iters: 560, time: 0.105, data: 0.001) G_GAN: 2.421 G_L1: 10.451 D_real: 0.148 D_fake: 0.126 \n",
      "(epoch: 21, iters: 660, time: 0.375, data: 0.002) G_GAN: 1.315 G_L1: 9.645 D_real: 1.634 D_fake: 0.179 \n",
      "(epoch: 21, iters: 760, time: 0.103, data: 0.001) G_GAN: 2.005 G_L1: 27.605 D_real: 0.251 D_fake: 0.146 \n",
      "End of epoch 21 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 22, iters: 93, time: 0.106, data: 0.002) G_GAN: 1.502 G_L1: 14.308 D_real: 0.222 D_fake: 0.492 \n",
      "(epoch: 22, iters: 193, time: 0.105, data: 0.001) G_GAN: 2.735 G_L1: 6.620 D_real: 0.020 D_fake: 0.148 \n",
      "(epoch: 22, iters: 293, time: 0.388, data: 0.002) G_GAN: 2.222 G_L1: 15.969 D_real: 0.282 D_fake: 0.194 \n",
      "(epoch: 22, iters: 393, time: 0.105, data: 0.002) G_GAN: 2.893 G_L1: 17.354 D_real: 0.127 D_fake: 0.172 \n",
      "(epoch: 22, iters: 493, time: 0.105, data: 0.001) G_GAN: 1.421 G_L1: 12.035 D_real: 0.195 D_fake: 0.451 \n",
      "(epoch: 22, iters: 593, time: 0.104, data: 0.001) G_GAN: 2.738 G_L1: 12.960 D_real: 0.131 D_fake: 0.099 \n",
      "(epoch: 22, iters: 693, time: 0.209, data: 0.001) G_GAN: 1.142 G_L1: 10.882 D_real: 0.837 D_fake: 0.197 \n",
      "End of epoch 22 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 23, iters: 26, time: 0.103, data: 0.001) G_GAN: 2.202 G_L1: 7.696 D_real: 0.215 D_fake: 0.296 \n",
      "(epoch: 23, iters: 126, time: 0.101, data: 0.001) G_GAN: 2.042 G_L1: 11.103 D_real: 0.039 D_fake: 0.376 \n",
      "(epoch: 23, iters: 226, time: 0.106, data: 0.001) G_GAN: 1.305 G_L1: 19.822 D_real: 0.037 D_fake: 0.621 \n",
      "(epoch: 23, iters: 326, time: 0.380, data: 0.001) G_GAN: 1.275 G_L1: 8.224 D_real: 1.203 D_fake: 0.061 \n",
      "(epoch: 23, iters: 426, time: 0.102, data: 0.001) G_GAN: 2.087 G_L1: 16.936 D_real: 0.394 D_fake: 0.227 \n",
      "(epoch: 23, iters: 526, time: 0.105, data: 0.001) G_GAN: 2.060 G_L1: 9.478 D_real: 0.159 D_fake: 0.561 \n",
      "(epoch: 23, iters: 626, time: 0.105, data: 0.001) G_GAN: 1.877 G_L1: 8.486 D_real: 0.095 D_fake: 1.046 \n",
      "(epoch: 23, iters: 726, time: 0.207, data: 0.002) G_GAN: 2.132 G_L1: 18.292 D_real: 0.498 D_fake: 0.275 \n",
      "End of epoch 23 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 24, iters: 59, time: 0.103, data: 0.001) G_GAN: 1.217 G_L1: 10.368 D_real: 0.081 D_fake: 0.601 \n",
      "(epoch: 24, iters: 159, time: 0.103, data: 0.001) G_GAN: 4.324 G_L1: 17.569 D_real: 0.371 D_fake: 0.019 \n",
      "(epoch: 24, iters: 259, time: 0.105, data: 0.001) G_GAN: 0.894 G_L1: 8.465 D_real: 0.788 D_fake: 0.677 \n",
      "(epoch: 24, iters: 359, time: 0.391, data: 0.001) G_GAN: 2.461 G_L1: 23.067 D_real: 1.162 D_fake: 0.062 \n",
      "(epoch: 24, iters: 459, time: 0.104, data: 0.002) G_GAN: 1.095 G_L1: 10.754 D_real: 1.765 D_fake: 0.182 \n",
      "(epoch: 24, iters: 559, time: 0.105, data: 0.001) G_GAN: 2.827 G_L1: 15.494 D_real: 0.930 D_fake: 0.043 \n",
      "(epoch: 24, iters: 659, time: 0.104, data: 0.001) G_GAN: 1.511 G_L1: 18.540 D_real: 0.450 D_fake: 0.780 \n",
      "(epoch: 24, iters: 759, time: 0.205, data: 0.001) G_GAN: 3.768 G_L1: 13.195 D_real: 0.170 D_fake: 0.029 \n",
      "End of epoch 24 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 25, iters: 92, time: 0.104, data: 0.001) G_GAN: 2.042 G_L1: 19.380 D_real: 0.011 D_fake: 1.249 \n",
      "(epoch: 25, iters: 192, time: 0.104, data: 0.001) G_GAN: 2.381 G_L1: 20.322 D_real: 0.093 D_fake: 0.159 \n",
      "(epoch: 25, iters: 292, time: 0.104, data: 0.001) G_GAN: 2.643 G_L1: 13.823 D_real: 0.004 D_fake: 0.525 \n",
      "(epoch: 25, iters: 392, time: 0.382, data: 0.001) G_GAN: 1.375 G_L1: 14.296 D_real: 0.514 D_fake: 0.283 \n",
      "(epoch: 25, iters: 492, time: 0.104, data: 0.002) G_GAN: 3.512 G_L1: 22.147 D_real: 0.472 D_fake: 0.019 \n",
      "(epoch: 25, iters: 592, time: 0.105, data: 0.001) G_GAN: 2.440 G_L1: 22.120 D_real: 0.009 D_fake: 0.950 \n",
      "(epoch: 25, iters: 692, time: 0.091, data: 0.001) G_GAN: 1.239 G_L1: 13.405 D_real: 0.677 D_fake: 0.371 \n",
      "saving the model at the end of epoch 25, iters 19175\n",
      "End of epoch 25 / 200 \t Time Taken: 51 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 26, iters: 25, time: 0.407, data: 0.001) G_GAN: 2.085 G_L1: 8.624 D_real: 0.994 D_fake: 0.063 \n",
      "(epoch: 26, iters: 125, time: 0.094, data: 0.001) G_GAN: 2.883 G_L1: 22.498 D_real: 0.027 D_fake: 0.108 \n",
      "(epoch: 26, iters: 225, time: 0.105, data: 0.002) G_GAN: 2.098 G_L1: 16.807 D_real: 1.158 D_fake: 0.088 \n",
      "(epoch: 26, iters: 325, time: 0.099, data: 0.001) G_GAN: 1.858 G_L1: 10.337 D_real: 0.775 D_fake: 0.039 \n",
      "(epoch: 26, iters: 425, time: 0.211, data: 0.001) G_GAN: 3.530 G_L1: 24.301 D_real: 0.019 D_fake: 0.052 \n",
      "(epoch: 26, iters: 525, time: 0.105, data: 0.002) G_GAN: 2.037 G_L1: 10.707 D_real: 0.018 D_fake: 1.557 \n",
      "(epoch: 26, iters: 625, time: 0.106, data: 0.002) G_GAN: 2.778 G_L1: 13.654 D_real: 0.221 D_fake: 0.097 \n",
      "(epoch: 26, iters: 725, time: 0.105, data: 0.002) G_GAN: 1.980 G_L1: 13.299 D_real: 0.120 D_fake: 0.908 \n",
      "End of epoch 26 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 27, iters: 58, time: 0.389, data: 0.001) G_GAN: 1.887 G_L1: 12.044 D_real: 0.216 D_fake: 0.940 \n",
      "saving the latest model (epoch 27, total_iters 20000)\n",
      "(epoch: 27, iters: 158, time: 0.105, data: 0.002) G_GAN: 2.496 G_L1: 23.273 D_real: 0.004 D_fake: 1.407 \n",
      "(epoch: 27, iters: 258, time: 0.105, data: 0.001) G_GAN: 2.851 G_L1: 13.257 D_real: 0.045 D_fake: 0.469 \n",
      "(epoch: 27, iters: 358, time: 0.104, data: 0.001) G_GAN: 1.921 G_L1: 11.498 D_real: 0.556 D_fake: 0.074 \n",
      "(epoch: 27, iters: 458, time: 0.206, data: 0.002) G_GAN: 1.724 G_L1: 12.406 D_real: 0.136 D_fake: 0.368 \n",
      "(epoch: 27, iters: 558, time: 0.106, data: 0.002) G_GAN: 3.232 G_L1: 13.396 D_real: 0.094 D_fake: 0.080 \n",
      "(epoch: 27, iters: 658, time: 0.105, data: 0.001) G_GAN: 1.890 G_L1: 8.842 D_real: 0.167 D_fake: 0.704 \n",
      "(epoch: 27, iters: 758, time: 0.105, data: 0.001) G_GAN: 1.364 G_L1: 9.658 D_real: 1.267 D_fake: 0.086 \n",
      "End of epoch 27 / 200 \t Time Taken: 50 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 28, iters: 91, time: 0.398, data: 0.001) G_GAN: 2.301 G_L1: 12.044 D_real: 0.318 D_fake: 0.114 \n",
      "(epoch: 28, iters: 191, time: 0.103, data: 0.001) G_GAN: 3.103 G_L1: 10.803 D_real: 0.211 D_fake: 0.070 \n",
      "(epoch: 28, iters: 291, time: 0.105, data: 0.001) G_GAN: 2.736 G_L1: 11.743 D_real: 0.191 D_fake: 0.107 \n",
      "(epoch: 28, iters: 391, time: 0.104, data: 0.001) G_GAN: 1.749 G_L1: 14.946 D_real: 0.038 D_fake: 1.843 \n",
      "(epoch: 28, iters: 491, time: 0.203, data: 0.001) G_GAN: 2.529 G_L1: 7.896 D_real: 0.050 D_fake: 0.357 \n",
      "(epoch: 28, iters: 591, time: 0.105, data: 0.001) G_GAN: 1.339 G_L1: 15.538 D_real: 0.186 D_fake: 0.870 \n",
      "(epoch: 28, iters: 691, time: 0.104, data: 0.001) G_GAN: 1.563 G_L1: 21.398 D_real: 0.603 D_fake: 0.086 \n",
      "End of epoch 28 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 29, iters: 24, time: 0.103, data: 0.002) G_GAN: 2.234 G_L1: 14.978 D_real: 0.105 D_fake: 0.115 \n",
      "(epoch: 29, iters: 124, time: 0.447, data: 0.001) G_GAN: 1.698 G_L1: 25.707 D_real: 0.988 D_fake: 0.112 \n",
      "(epoch: 29, iters: 224, time: 0.105, data: 0.001) G_GAN: 1.985 G_L1: 16.114 D_real: 0.592 D_fake: 0.136 \n",
      "(epoch: 29, iters: 324, time: 0.105, data: 0.001) G_GAN: 2.081 G_L1: 9.200 D_real: 0.050 D_fake: 0.696 \n",
      "(epoch: 29, iters: 424, time: 0.104, data: 0.001) G_GAN: 2.217 G_L1: 8.608 D_real: 0.081 D_fake: 0.468 \n",
      "(epoch: 29, iters: 524, time: 0.399, data: 0.001) G_GAN: 2.225 G_L1: 9.712 D_real: 0.095 D_fake: 0.536 \n",
      "(epoch: 29, iters: 624, time: 0.105, data: 0.002) G_GAN: 2.124 G_L1: 11.195 D_real: 0.250 D_fake: 0.393 \n",
      "(epoch: 29, iters: 724, time: 0.104, data: 0.001) G_GAN: 2.376 G_L1: 14.015 D_real: 0.061 D_fake: 0.987 \n",
      "End of epoch 29 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 30, iters: 57, time: 0.103, data: 0.001) G_GAN: 1.807 G_L1: 10.136 D_real: 0.968 D_fake: 0.059 \n",
      "(epoch: 30, iters: 157, time: 0.404, data: 0.001) G_GAN: 2.481 G_L1: 24.563 D_real: 0.048 D_fake: 0.219 \n",
      "(epoch: 30, iters: 257, time: 0.106, data: 0.002) G_GAN: 1.775 G_L1: 9.460 D_real: 0.751 D_fake: 0.121 \n",
      "(epoch: 30, iters: 357, time: 0.103, data: 0.002) G_GAN: 2.273 G_L1: 16.994 D_real: 0.078 D_fake: 0.385 \n",
      "(epoch: 30, iters: 457, time: 0.104, data: 0.001) G_GAN: 2.214 G_L1: 24.389 D_real: 0.150 D_fake: 0.437 \n",
      "(epoch: 30, iters: 557, time: 0.198, data: 0.001) G_GAN: 1.324 G_L1: 7.510 D_real: 0.368 D_fake: 1.021 \n",
      "(epoch: 30, iters: 657, time: 0.105, data: 0.002) G_GAN: 2.122 G_L1: 10.943 D_real: 0.086 D_fake: 1.019 \n",
      "(epoch: 30, iters: 757, time: 0.106, data: 0.002) G_GAN: 2.183 G_L1: 15.528 D_real: 0.033 D_fake: 1.953 \n",
      "saving the model at the end of epoch 30, iters 23010\n",
      "End of epoch 30 / 200 \t Time Taken: 51 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 31, iters: 90, time: 0.104, data: 0.001) G_GAN: 1.798 G_L1: 11.385 D_real: 0.415 D_fake: 0.969 \n",
      "(epoch: 31, iters: 190, time: 0.403, data: 0.001) G_GAN: 1.267 G_L1: 15.196 D_real: 0.387 D_fake: 0.324 \n",
      "(epoch: 31, iters: 290, time: 0.104, data: 0.001) G_GAN: 2.115 G_L1: 16.441 D_real: 0.038 D_fake: 0.331 \n",
      "(epoch: 31, iters: 390, time: 0.106, data: 0.002) G_GAN: 1.227 G_L1: 6.880 D_real: 0.671 D_fake: 0.363 \n",
      "(epoch: 31, iters: 490, time: 0.105, data: 0.001) G_GAN: 1.657 G_L1: 14.231 D_real: 0.363 D_fake: 0.270 \n",
      "(epoch: 31, iters: 590, time: 0.218, data: 0.001) G_GAN: 2.600 G_L1: 6.506 D_real: 0.210 D_fake: 0.108 \n",
      "(epoch: 31, iters: 690, time: 0.105, data: 0.002) G_GAN: 1.359 G_L1: 8.057 D_real: 0.374 D_fake: 0.407 \n",
      "End of epoch 31 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 32, iters: 23, time: 0.103, data: 0.001) G_GAN: 1.422 G_L1: 9.928 D_real: 0.273 D_fake: 0.315 \n",
      "(epoch: 32, iters: 123, time: 0.104, data: 0.001) G_GAN: 2.437 G_L1: 19.946 D_real: 0.617 D_fake: 0.039 \n",
      "(epoch: 32, iters: 223, time: 0.417, data: 0.001) G_GAN: 2.858 G_L1: 10.232 D_real: 0.030 D_fake: 0.397 \n",
      "(epoch: 32, iters: 323, time: 0.103, data: 0.002) G_GAN: 3.194 G_L1: 13.223 D_real: 0.043 D_fake: 0.386 \n",
      "(epoch: 32, iters: 423, time: 0.103, data: 0.001) G_GAN: 2.032 G_L1: 9.574 D_real: 0.118 D_fake: 0.246 \n",
      "(epoch: 32, iters: 523, time: 0.105, data: 0.001) G_GAN: 1.280 G_L1: 9.193 D_real: 0.618 D_fake: 0.213 \n",
      "(epoch: 32, iters: 623, time: 0.208, data: 0.001) G_GAN: 1.217 G_L1: 9.818 D_real: 0.485 D_fake: 0.247 \n",
      "(epoch: 32, iters: 723, time: 0.104, data: 0.001) G_GAN: 0.843 G_L1: 11.845 D_real: 1.278 D_fake: 0.347 \n",
      "End of epoch 32 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 33, iters: 56, time: 0.104, data: 0.001) G_GAN: 2.475 G_L1: 24.106 D_real: 0.001 D_fake: 0.237 \n",
      "(epoch: 33, iters: 156, time: 0.104, data: 0.001) G_GAN: 2.099 G_L1: 19.908 D_real: 0.007 D_fake: 0.428 \n",
      "(epoch: 33, iters: 256, time: 0.415, data: 0.001) G_GAN: 3.119 G_L1: 17.216 D_real: 0.285 D_fake: 0.039 \n",
      "(epoch: 33, iters: 356, time: 0.103, data: 0.002) G_GAN: 2.391 G_L1: 18.201 D_real: 0.037 D_fake: 0.445 \n",
      "(epoch: 33, iters: 456, time: 0.100, data: 0.004) G_GAN: 2.507 G_L1: 10.890 D_real: 0.535 D_fake: 0.054 \n",
      "saving the latest model (epoch 33, total_iters 25000)\n",
      "(epoch: 33, iters: 556, time: 0.091, data: 0.002) G_GAN: 2.157 G_L1: 19.358 D_real: 0.045 D_fake: 0.314 \n",
      "(epoch: 33, iters: 656, time: 0.217, data: 0.001) G_GAN: 1.941 G_L1: 9.551 D_real: 0.232 D_fake: 0.147 \n",
      "(epoch: 33, iters: 756, time: 0.106, data: 0.001) G_GAN: 2.466 G_L1: 14.119 D_real: 0.019 D_fake: 0.519 \n",
      "End of epoch 33 / 200 \t Time Taken: 50 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 34, iters: 89, time: 0.103, data: 0.001) G_GAN: 2.784 G_L1: 18.964 D_real: 0.181 D_fake: 0.086 \n",
      "(epoch: 34, iters: 189, time: 0.105, data: 0.001) G_GAN: 1.657 G_L1: 13.399 D_real: 0.416 D_fake: 0.227 \n",
      "(epoch: 34, iters: 289, time: 0.396, data: 0.001) G_GAN: 2.512 G_L1: 18.248 D_real: 0.052 D_fake: 0.093 \n",
      "(epoch: 34, iters: 389, time: 0.105, data: 0.002) G_GAN: 1.912 G_L1: 15.011 D_real: 0.988 D_fake: 0.210 \n",
      "(epoch: 34, iters: 489, time: 0.104, data: 0.002) G_GAN: 3.337 G_L1: 16.021 D_real: 0.006 D_fake: 0.153 \n",
      "(epoch: 34, iters: 589, time: 0.104, data: 0.001) G_GAN: 1.473 G_L1: 8.916 D_real: 1.596 D_fake: 0.035 \n",
      "(epoch: 34, iters: 689, time: 0.408, data: 0.001) G_GAN: 2.947 G_L1: 13.685 D_real: 0.155 D_fake: 0.066 \n",
      "End of epoch 34 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 35, iters: 22, time: 0.103, data: 0.002) G_GAN: 2.844 G_L1: 15.033 D_real: 0.198 D_fake: 0.084 \n",
      "(epoch: 35, iters: 122, time: 0.105, data: 0.001) G_GAN: 1.968 G_L1: 9.362 D_real: 0.330 D_fake: 0.286 \n",
      "(epoch: 35, iters: 222, time: 0.105, data: 0.001) G_GAN: 2.008 G_L1: 17.935 D_real: 0.016 D_fake: 0.710 \n",
      "(epoch: 35, iters: 322, time: 0.431, data: 0.001) G_GAN: 1.597 G_L1: 10.059 D_real: 1.895 D_fake: 0.043 \n",
      "(epoch: 35, iters: 422, time: 0.100, data: 0.001) G_GAN: 2.592 G_L1: 6.995 D_real: 0.180 D_fake: 0.507 \n",
      "(epoch: 35, iters: 522, time: 0.098, data: 0.001) G_GAN: 2.943 G_L1: 11.315 D_real: 1.040 D_fake: 0.044 \n",
      "(epoch: 35, iters: 622, time: 0.104, data: 0.001) G_GAN: 3.533 G_L1: 28.046 D_real: 0.001 D_fake: 0.123 \n",
      "(epoch: 35, iters: 722, time: 0.217, data: 0.001) G_GAN: 3.085 G_L1: 16.949 D_real: 0.167 D_fake: 0.079 \n",
      "saving the model at the end of epoch 35, iters 26845\n",
      "End of epoch 35 / 200 \t Time Taken: 51 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 36, iters: 55, time: 0.104, data: 0.001) G_GAN: 2.727 G_L1: 19.836 D_real: 0.698 D_fake: 0.106 \n",
      "(epoch: 36, iters: 155, time: 0.094, data: 0.002) G_GAN: 3.015 G_L1: 15.236 D_real: 0.625 D_fake: 0.032 \n",
      "(epoch: 36, iters: 255, time: 0.104, data: 0.002) G_GAN: 2.841 G_L1: 12.281 D_real: 0.224 D_fake: 0.117 \n",
      "(epoch: 36, iters: 355, time: 0.430, data: 0.002) G_GAN: 3.256 G_L1: 13.891 D_real: 0.282 D_fake: 0.051 \n",
      "(epoch: 36, iters: 455, time: 0.104, data: 0.002) G_GAN: 4.810 G_L1: 14.263 D_real: 0.017 D_fake: 0.017 \n",
      "(epoch: 36, iters: 555, time: 0.105, data: 0.001) G_GAN: 2.473 G_L1: 14.440 D_real: 0.172 D_fake: 0.060 \n",
      "(epoch: 36, iters: 655, time: 0.104, data: 0.001) G_GAN: 0.714 G_L1: 7.945 D_real: 1.317 D_fake: 0.129 \n",
      "(epoch: 36, iters: 755, time: 0.210, data: 0.001) G_GAN: 3.317 G_L1: 15.202 D_real: 0.061 D_fake: 0.144 \n",
      "End of epoch 36 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 37, iters: 88, time: 0.105, data: 0.002) G_GAN: 0.436 G_L1: 8.738 D_real: 0.978 D_fake: 0.306 \n",
      "(epoch: 37, iters: 188, time: 0.103, data: 0.001) G_GAN: 1.588 G_L1: 15.937 D_real: 0.879 D_fake: 0.392 \n",
      "(epoch: 37, iters: 288, time: 0.105, data: 0.001) G_GAN: 1.897 G_L1: 8.418 D_real: 0.634 D_fake: 0.403 \n",
      "(epoch: 37, iters: 388, time: 0.441, data: 0.001) G_GAN: 1.554 G_L1: 9.242 D_real: 0.322 D_fake: 0.270 \n",
      "(epoch: 37, iters: 488, time: 0.103, data: 0.002) G_GAN: 2.242 G_L1: 17.752 D_real: 0.049 D_fake: 0.145 \n",
      "(epoch: 37, iters: 588, time: 0.105, data: 0.001) G_GAN: 2.000 G_L1: 11.713 D_real: 0.247 D_fake: 0.501 \n",
      "(epoch: 37, iters: 688, time: 0.100, data: 0.001) G_GAN: 1.954 G_L1: 14.887 D_real: 0.006 D_fake: 1.197 \n",
      "End of epoch 37 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 38, iters: 21, time: 0.445, data: 0.002) G_GAN: 2.575 G_L1: 16.486 D_real: 0.003 D_fake: 0.140 \n",
      "(epoch: 38, iters: 121, time: 0.105, data: 0.002) G_GAN: 2.588 G_L1: 17.984 D_real: 0.053 D_fake: 0.118 \n",
      "(epoch: 38, iters: 221, time: 0.104, data: 0.001) G_GAN: 2.568 G_L1: 13.758 D_real: 0.291 D_fake: 0.796 \n",
      "(epoch: 38, iters: 321, time: 0.105, data: 0.001) G_GAN: 2.102 G_L1: 11.744 D_real: 0.121 D_fake: 0.220 \n",
      "(epoch: 38, iters: 421, time: 0.209, data: 0.001) G_GAN: 3.172 G_L1: 22.772 D_real: 0.087 D_fake: 0.115 \n",
      "(epoch: 38, iters: 521, time: 0.106, data: 0.002) G_GAN: 2.765 G_L1: 8.641 D_real: 0.022 D_fake: 1.361 \n",
      "(epoch: 38, iters: 621, time: 0.104, data: 0.001) G_GAN: 3.027 G_L1: 15.864 D_real: 0.018 D_fake: 0.249 \n",
      "(epoch: 38, iters: 721, time: 0.105, data: 0.002) G_GAN: 2.199 G_L1: 15.367 D_real: 0.284 D_fake: 0.417 \n",
      "End of epoch 38 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 39, iters: 54, time: 0.421, data: 0.001) G_GAN: 2.139 G_L1: 18.732 D_real: 0.134 D_fake: 0.280 \n",
      "(epoch: 39, iters: 154, time: 0.104, data: 0.001) G_GAN: 2.449 G_L1: 11.054 D_real: 0.027 D_fake: 0.128 \n",
      "(epoch: 39, iters: 254, time: 0.101, data: 0.001) G_GAN: 2.343 G_L1: 22.096 D_real: 0.000 D_fake: 1.291 \n",
      "(epoch: 39, iters: 354, time: 0.105, data: 0.001) G_GAN: 2.355 G_L1: 12.446 D_real: 0.797 D_fake: 0.154 \n",
      "(epoch: 39, iters: 454, time: 0.227, data: 0.001) G_GAN: 1.036 G_L1: 11.029 D_real: 1.520 D_fake: 0.991 \n",
      "(epoch: 39, iters: 554, time: 0.104, data: 0.002) G_GAN: 2.038 G_L1: 18.477 D_real: 1.574 D_fake: 0.041 \n",
      "(epoch: 39, iters: 654, time: 0.103, data: 0.001) G_GAN: 2.317 G_L1: 23.375 D_real: 0.013 D_fake: 0.232 \n",
      "(epoch: 39, iters: 754, time: 0.106, data: 0.001) G_GAN: 3.073 G_L1: 15.564 D_real: 0.122 D_fake: 0.068 \n",
      "End of epoch 39 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 40, iters: 87, time: 0.422, data: 0.001) G_GAN: 1.794 G_L1: 10.812 D_real: 0.144 D_fake: 0.306 \n",
      "saving the latest model (epoch 40, total_iters 30000)\n",
      "(epoch: 40, iters: 187, time: 0.104, data: 0.002) G_GAN: 2.191 G_L1: 13.643 D_real: 0.043 D_fake: 1.715 \n",
      "(epoch: 40, iters: 287, time: 0.103, data: 0.002) G_GAN: 2.326 G_L1: 14.405 D_real: 0.075 D_fake: 1.767 \n",
      "(epoch: 40, iters: 387, time: 0.103, data: 0.001) G_GAN: 0.676 G_L1: 9.293 D_real: 0.984 D_fake: 0.341 \n",
      "(epoch: 40, iters: 487, time: 0.213, data: 0.001) G_GAN: 2.574 G_L1: 12.838 D_real: 0.115 D_fake: 0.154 \n",
      "(epoch: 40, iters: 587, time: 0.103, data: 0.001) G_GAN: 1.068 G_L1: 12.274 D_real: 0.862 D_fake: 0.204 \n",
      "(epoch: 40, iters: 687, time: 0.104, data: 0.001) G_GAN: 3.420 G_L1: 14.387 D_real: 0.178 D_fake: 0.050 \n",
      "saving the model at the end of epoch 40, iters 30680\n",
      "End of epoch 40 / 200 \t Time Taken: 52 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 41, iters: 20, time: 0.105, data: 0.001) G_GAN: 3.494 G_L1: 11.125 D_real: 0.123 D_fake: 1.170 \n",
      "(epoch: 41, iters: 120, time: 0.502, data: 0.001) G_GAN: 1.032 G_L1: 8.637 D_real: 1.061 D_fake: 0.171 \n",
      "(epoch: 41, iters: 220, time: 0.104, data: 0.002) G_GAN: 2.120 G_L1: 15.481 D_real: 0.002 D_fake: 0.222 \n",
      "(epoch: 41, iters: 320, time: 0.104, data: 0.001) G_GAN: 1.161 G_L1: 8.709 D_real: 0.907 D_fake: 0.655 \n",
      "(epoch: 41, iters: 420, time: 0.100, data: 0.001) G_GAN: 0.766 G_L1: 7.455 D_real: 0.684 D_fake: 0.292 \n",
      "(epoch: 41, iters: 520, time: 0.223, data: 0.001) G_GAN: 2.255 G_L1: 15.704 D_real: 0.067 D_fake: 0.348 \n",
      "(epoch: 41, iters: 620, time: 0.104, data: 0.002) G_GAN: 2.280 G_L1: 12.056 D_real: 0.121 D_fake: 0.317 \n",
      "(epoch: 41, iters: 720, time: 0.105, data: 0.001) G_GAN: 2.894 G_L1: 16.154 D_real: 0.052 D_fake: 0.446 \n",
      "End of epoch 41 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 42, iters: 53, time: 0.101, data: 0.001) G_GAN: 1.656 G_L1: 6.730 D_real: 0.458 D_fake: 0.327 \n",
      "(epoch: 42, iters: 153, time: 0.460, data: 0.001) G_GAN: 3.862 G_L1: 18.206 D_real: 0.007 D_fake: 0.040 \n",
      "(epoch: 42, iters: 253, time: 0.093, data: 0.002) G_GAN: 1.852 G_L1: 14.205 D_real: 0.202 D_fake: 0.279 \n",
      "(epoch: 42, iters: 353, time: 0.104, data: 0.002) G_GAN: 2.344 G_L1: 10.612 D_real: 0.121 D_fake: 0.405 \n",
      "(epoch: 42, iters: 453, time: 0.106, data: 0.001) G_GAN: 3.018 G_L1: 20.586 D_real: 0.014 D_fake: 0.092 \n",
      "(epoch: 42, iters: 553, time: 0.446, data: 0.001) G_GAN: 2.575 G_L1: 10.652 D_real: 0.077 D_fake: 1.041 \n",
      "(epoch: 42, iters: 653, time: 0.105, data: 0.001) G_GAN: 2.241 G_L1: 21.925 D_real: 0.329 D_fake: 0.217 \n",
      "(epoch: 42, iters: 753, time: 0.104, data: 0.001) G_GAN: 2.025 G_L1: 9.979 D_real: 0.130 D_fake: 0.643 \n",
      "End of epoch 42 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 43, iters: 86, time: 0.105, data: 0.002) G_GAN: 2.286 G_L1: 17.689 D_real: 0.421 D_fake: 0.094 \n",
      "(epoch: 43, iters: 186, time: 0.419, data: 0.001) G_GAN: 3.076 G_L1: 23.756 D_real: 0.010 D_fake: 0.235 \n",
      "(epoch: 43, iters: 286, time: 0.106, data: 0.001) G_GAN: 4.984 G_L1: 18.471 D_real: 0.036 D_fake: 0.012 \n",
      "(epoch: 43, iters: 386, time: 0.105, data: 0.001) G_GAN: 3.635 G_L1: 15.043 D_real: 0.006 D_fake: 1.492 \n",
      "(epoch: 43, iters: 486, time: 0.100, data: 0.001) G_GAN: 2.255 G_L1: 8.635 D_real: 0.344 D_fake: 0.288 \n",
      "(epoch: 43, iters: 586, time: 0.208, data: 0.001) G_GAN: 1.435 G_L1: 10.386 D_real: 0.592 D_fake: 0.197 \n",
      "(epoch: 43, iters: 686, time: 0.104, data: 0.001) G_GAN: 2.879 G_L1: 17.302 D_real: 0.772 D_fake: 0.460 \n",
      "End of epoch 43 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 44, iters: 19, time: 0.101, data: 0.001) G_GAN: 3.455 G_L1: 20.593 D_real: 0.041 D_fake: 0.104 \n",
      "(epoch: 44, iters: 119, time: 0.105, data: 0.001) G_GAN: 2.511 G_L1: 18.567 D_real: 0.171 D_fake: 0.524 \n",
      "(epoch: 44, iters: 219, time: 0.437, data: 0.001) G_GAN: 1.578 G_L1: 14.161 D_real: 1.267 D_fake: 0.179 \n",
      "(epoch: 44, iters: 319, time: 0.105, data: 0.002) G_GAN: 2.910 G_L1: 11.253 D_real: 0.102 D_fake: 0.109 \n",
      "(epoch: 44, iters: 419, time: 0.105, data: 0.001) G_GAN: 5.130 G_L1: 10.577 D_real: 0.010 D_fake: 1.652 \n",
      "(epoch: 44, iters: 519, time: 0.104, data: 0.001) G_GAN: 6.122 G_L1: 15.715 D_real: 0.032 D_fake: 0.004 \n",
      "(epoch: 44, iters: 619, time: 0.213, data: 0.001) G_GAN: 0.861 G_L1: 9.340 D_real: 1.084 D_fake: 0.182 \n",
      "(epoch: 44, iters: 719, time: 0.101, data: 0.002) G_GAN: 3.364 G_L1: 13.295 D_real: 0.072 D_fake: 0.090 \n",
      "End of epoch 44 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 45, iters: 52, time: 0.105, data: 0.001) G_GAN: 3.025 G_L1: 18.109 D_real: 0.495 D_fake: 0.056 \n",
      "(epoch: 45, iters: 152, time: 0.104, data: 0.001) G_GAN: 2.802 G_L1: 11.189 D_real: 0.010 D_fake: 0.466 \n",
      "(epoch: 45, iters: 252, time: 0.443, data: 0.001) G_GAN: 1.582 G_L1: 15.619 D_real: 0.618 D_fake: 0.143 \n",
      "(epoch: 45, iters: 352, time: 0.102, data: 0.001) G_GAN: 2.653 G_L1: 12.924 D_real: 0.295 D_fake: 0.134 \n",
      "(epoch: 45, iters: 452, time: 0.104, data: 0.001) G_GAN: 1.781 G_L1: 15.197 D_real: 0.579 D_fake: 0.085 \n",
      "(epoch: 45, iters: 552, time: 0.105, data: 0.001) G_GAN: 1.955 G_L1: 7.639 D_real: 1.179 D_fake: 0.017 \n",
      "(epoch: 45, iters: 652, time: 0.212, data: 0.001) G_GAN: 2.546 G_L1: 9.613 D_real: 0.125 D_fake: 0.249 \n",
      "(epoch: 45, iters: 752, time: 0.106, data: 0.001) G_GAN: 2.570 G_L1: 18.818 D_real: 0.009 D_fake: 0.278 \n",
      "saving the model at the end of epoch 45, iters 34515\n",
      "End of epoch 45 / 200 \t Time Taken: 51 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 46, iters: 85, time: 0.094, data: 0.001) G_GAN: 1.197 G_L1: 8.034 D_real: 0.689 D_fake: 0.262 \n",
      "(epoch: 46, iters: 185, time: 0.104, data: 0.002) G_GAN: 2.651 G_L1: 8.452 D_real: 0.036 D_fake: 0.887 \n",
      "(epoch: 46, iters: 285, time: 0.488, data: 0.001) G_GAN: 2.546 G_L1: 13.743 D_real: 1.138 D_fake: 0.034 \n",
      "(epoch: 46, iters: 385, time: 0.104, data: 0.001) G_GAN: 2.890 G_L1: 23.224 D_real: 0.003 D_fake: 0.187 \n",
      "(epoch: 46, iters: 485, time: 0.105, data: 0.001) G_GAN: 2.508 G_L1: 14.505 D_real: 0.146 D_fake: 0.175 \n",
      "saving the latest model (epoch 46, total_iters 35000)\n",
      "(epoch: 46, iters: 585, time: 0.104, data: 0.002) G_GAN: 2.550 G_L1: 13.638 D_real: 0.026 D_fake: 0.195 \n",
      "(epoch: 46, iters: 685, time: 0.204, data: 0.001) G_GAN: 5.715 G_L1: 26.882 D_real: 0.113 D_fake: 0.008 \n",
      "End of epoch 46 / 200 \t Time Taken: 50 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 47, iters: 18, time: 0.105, data: 0.001) G_GAN: 1.712 G_L1: 8.620 D_real: 0.423 D_fake: 0.262 \n",
      "(epoch: 47, iters: 118, time: 0.105, data: 0.001) G_GAN: 1.972 G_L1: 9.729 D_real: 0.069 D_fake: 0.469 \n",
      "(epoch: 47, iters: 218, time: 0.104, data: 0.001) G_GAN: 1.940 G_L1: 9.409 D_real: 0.100 D_fake: 0.138 \n",
      "(epoch: 47, iters: 318, time: 0.452, data: 0.001) G_GAN: 3.422 G_L1: 18.856 D_real: 0.011 D_fake: 0.656 \n",
      "(epoch: 47, iters: 418, time: 0.103, data: 0.001) G_GAN: 1.922 G_L1: 8.567 D_real: 0.176 D_fake: 0.179 \n",
      "(epoch: 47, iters: 518, time: 0.105, data: 0.001) G_GAN: 2.664 G_L1: 20.674 D_real: 0.119 D_fake: 0.136 \n",
      "(epoch: 47, iters: 618, time: 0.104, data: 0.004) G_GAN: 3.101 G_L1: 13.069 D_real: 0.119 D_fake: 0.191 \n",
      "(epoch: 47, iters: 718, time: 0.431, data: 0.001) G_GAN: 2.438 G_L1: 8.139 D_real: 0.185 D_fake: 0.755 \n",
      "End of epoch 47 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 48, iters: 51, time: 0.104, data: 0.001) G_GAN: 1.620 G_L1: 8.963 D_real: 0.272 D_fake: 0.335 \n",
      "(epoch: 48, iters: 151, time: 0.105, data: 0.001) G_GAN: 4.384 G_L1: 17.643 D_real: 0.218 D_fake: 0.044 \n",
      "(epoch: 48, iters: 251, time: 0.104, data: 0.001) G_GAN: 2.681 G_L1: 14.644 D_real: 0.053 D_fake: 0.149 \n",
      "(epoch: 48, iters: 351, time: 0.457, data: 0.001) G_GAN: 2.414 G_L1: 11.956 D_real: 0.039 D_fake: 0.184 \n",
      "(epoch: 48, iters: 451, time: 0.105, data: 0.002) G_GAN: 1.893 G_L1: 18.070 D_real: 0.664 D_fake: 0.154 \n",
      "(epoch: 48, iters: 551, time: 0.105, data: 0.002) G_GAN: 0.469 G_L1: 10.579 D_real: 0.954 D_fake: 0.068 \n",
      "(epoch: 48, iters: 651, time: 0.103, data: 0.001) G_GAN: 5.047 G_L1: 16.056 D_real: 0.098 D_fake: 0.014 \n",
      "(epoch: 48, iters: 751, time: 0.201, data: 0.001) G_GAN: 2.765 G_L1: 9.524 D_real: 0.062 D_fake: 0.210 \n",
      "End of epoch 48 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 49, iters: 84, time: 0.106, data: 0.002) G_GAN: 2.972 G_L1: 9.358 D_real: 0.005 D_fake: 0.141 \n",
      "(epoch: 49, iters: 184, time: 0.105, data: 0.001) G_GAN: 1.565 G_L1: 10.691 D_real: 0.355 D_fake: 0.330 \n",
      "(epoch: 49, iters: 284, time: 0.104, data: 0.002) G_GAN: 2.286 G_L1: 16.784 D_real: 0.298 D_fake: 0.105 \n",
      "(epoch: 49, iters: 384, time: 0.452, data: 0.002) G_GAN: 4.464 G_L1: 20.409 D_real: 0.179 D_fake: 0.033 \n",
      "(epoch: 49, iters: 484, time: 0.103, data: 0.002) G_GAN: 3.265 G_L1: 19.687 D_real: 0.001 D_fake: 0.210 \n",
      "(epoch: 49, iters: 584, time: 0.104, data: 0.001) G_GAN: 3.278 G_L1: 17.695 D_real: 0.953 D_fake: 0.015 \n",
      "(epoch: 49, iters: 684, time: 0.104, data: 0.001) G_GAN: 3.225 G_L1: 22.670 D_real: 0.047 D_fake: 0.098 \n",
      "End of epoch 49 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 50, iters: 17, time: 0.457, data: 0.001) G_GAN: 3.681 G_L1: 9.256 D_real: 0.376 D_fake: 0.062 \n",
      "(epoch: 50, iters: 117, time: 0.104, data: 0.002) G_GAN: 3.939 G_L1: 13.317 D_real: 0.014 D_fake: 1.048 \n",
      "(epoch: 50, iters: 217, time: 0.103, data: 0.001) G_GAN: 2.691 G_L1: 11.717 D_real: 0.054 D_fake: 0.140 \n",
      "(epoch: 50, iters: 317, time: 0.101, data: 0.002) G_GAN: 1.825 G_L1: 6.408 D_real: 0.129 D_fake: 0.397 \n",
      "(epoch: 50, iters: 417, time: 0.441, data: 0.002) G_GAN: 1.355 G_L1: 7.469 D_real: 0.320 D_fake: 0.273 \n",
      "(epoch: 50, iters: 517, time: 0.103, data: 0.002) G_GAN: 3.944 G_L1: 23.635 D_real: 0.055 D_fake: 0.169 \n",
      "(epoch: 50, iters: 617, time: 0.104, data: 0.002) G_GAN: 5.712 G_L1: 19.672 D_real: 0.025 D_fake: 0.007 \n",
      "(epoch: 50, iters: 717, time: 0.105, data: 0.001) G_GAN: 2.618 G_L1: 13.180 D_real: 0.069 D_fake: 0.208 \n",
      "saving the model at the end of epoch 50, iters 38350\n",
      "End of epoch 50 / 200 \t Time Taken: 51 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 51, iters: 50, time: 0.478, data: 0.001) G_GAN: 2.413 G_L1: 19.053 D_real: 0.599 D_fake: 0.024 \n",
      "(epoch: 51, iters: 150, time: 0.093, data: 0.001) G_GAN: 3.579 G_L1: 12.732 D_real: 0.982 D_fake: 0.016 \n",
      "(epoch: 51, iters: 250, time: 0.098, data: 0.001) G_GAN: 1.504 G_L1: 8.142 D_real: 0.464 D_fake: 0.315 \n",
      "(epoch: 51, iters: 350, time: 0.103, data: 0.002) G_GAN: 2.469 G_L1: 15.168 D_real: 0.442 D_fake: 0.156 \n",
      "(epoch: 51, iters: 450, time: 0.218, data: 0.001) G_GAN: 0.969 G_L1: 8.647 D_real: 0.375 D_fake: 0.839 \n",
      "(epoch: 51, iters: 550, time: 0.102, data: 0.002) G_GAN: 2.715 G_L1: 17.641 D_real: 0.107 D_fake: 0.080 \n",
      "(epoch: 51, iters: 650, time: 0.102, data: 0.002) G_GAN: 2.779 G_L1: 13.233 D_real: 0.011 D_fake: 0.188 \n",
      "(epoch: 51, iters: 750, time: 0.103, data: 0.002) G_GAN: 2.205 G_L1: 4.935 D_real: 0.267 D_fake: 0.985 \n",
      "End of epoch 51 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 52, iters: 83, time: 0.491, data: 0.002) G_GAN: 1.917 G_L1: 8.190 D_real: 0.362 D_fake: 0.458 \n",
      "(epoch: 52, iters: 183, time: 0.103, data: 0.002) G_GAN: 1.874 G_L1: 12.682 D_real: 0.559 D_fake: 0.077 \n",
      "(epoch: 52, iters: 283, time: 0.104, data: 0.001) G_GAN: 3.382 G_L1: 20.690 D_real: 0.214 D_fake: 0.037 \n",
      "(epoch: 52, iters: 383, time: 0.104, data: 0.002) G_GAN: 3.775 G_L1: 16.262 D_real: 0.004 D_fake: 0.044 \n",
      "(epoch: 52, iters: 483, time: 0.206, data: 0.002) G_GAN: 2.411 G_L1: 6.437 D_real: 0.151 D_fake: 0.696 \n",
      "(epoch: 52, iters: 583, time: 0.105, data: 0.002) G_GAN: 1.550 G_L1: 11.941 D_real: 2.531 D_fake: 0.015 \n",
      "(epoch: 52, iters: 683, time: 0.105, data: 0.002) G_GAN: 1.960 G_L1: 10.136 D_real: 0.904 D_fake: 0.071 \n",
      "End of epoch 52 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 53, iters: 16, time: 0.111, data: 0.004) G_GAN: 1.551 G_L1: 6.698 D_real: 0.878 D_fake: 0.098 \n",
      "(epoch: 53, iters: 116, time: 0.460, data: 0.001) G_GAN: 2.183 G_L1: 16.759 D_real: 0.954 D_fake: 0.103 \n",
      "saving the latest model (epoch 53, total_iters 40000)\n",
      "(epoch: 53, iters: 216, time: 0.103, data: 0.002) G_GAN: 1.399 G_L1: 8.230 D_real: 0.885 D_fake: 0.316 \n",
      "(epoch: 53, iters: 316, time: 0.103, data: 0.001) G_GAN: 2.548 G_L1: 10.462 D_real: 0.005 D_fake: 0.297 \n",
      "(epoch: 53, iters: 416, time: 0.104, data: 0.002) G_GAN: 3.449 G_L1: 14.177 D_real: 0.034 D_fake: 0.190 \n",
      "(epoch: 53, iters: 516, time: 0.217, data: 0.001) G_GAN: 3.536 G_L1: 12.536 D_real: 0.078 D_fake: 0.354 \n",
      "(epoch: 53, iters: 616, time: 0.105, data: 0.002) G_GAN: 0.686 G_L1: 8.527 D_real: 2.445 D_fake: 0.054 \n",
      "(epoch: 53, iters: 716, time: 0.101, data: 0.001) G_GAN: 2.777 G_L1: 8.710 D_real: 0.160 D_fake: 0.240 \n",
      "End of epoch 53 / 200 \t Time Taken: 50 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 54, iters: 49, time: 0.104, data: 0.001) G_GAN: 0.861 G_L1: 7.886 D_real: 1.422 D_fake: 0.248 \n",
      "(epoch: 54, iters: 149, time: 0.491, data: 0.001) G_GAN: 2.942 G_L1: 20.262 D_real: 0.006 D_fake: 0.504 \n",
      "(epoch: 54, iters: 249, time: 0.105, data: 0.001) G_GAN: 1.609 G_L1: 7.550 D_real: 0.369 D_fake: 0.263 \n",
      "(epoch: 54, iters: 349, time: 0.102, data: 0.001) G_GAN: 1.273 G_L1: 6.071 D_real: 1.208 D_fake: 0.323 \n",
      "(epoch: 54, iters: 449, time: 0.104, data: 0.001) G_GAN: 3.437 G_L1: 10.936 D_real: 0.076 D_fake: 0.046 \n",
      "(epoch: 54, iters: 549, time: 0.215, data: 0.001) G_GAN: 5.387 G_L1: 14.982 D_real: 0.036 D_fake: 0.025 \n",
      "(epoch: 54, iters: 649, time: 0.106, data: 0.002) G_GAN: 3.267 G_L1: 13.638 D_real: 0.036 D_fake: 0.108 \n",
      "(epoch: 54, iters: 749, time: 0.105, data: 0.001) G_GAN: 5.025 G_L1: 13.974 D_real: 0.003 D_fake: 0.018 \n",
      "End of epoch 54 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 55, iters: 82, time: 0.105, data: 0.001) G_GAN: 3.976 G_L1: 13.023 D_real: 0.056 D_fake: 0.167 \n",
      "(epoch: 55, iters: 182, time: 0.480, data: 0.001) G_GAN: 3.289 G_L1: 12.541 D_real: 0.013 D_fake: 0.350 \n",
      "(epoch: 55, iters: 282, time: 0.104, data: 0.002) G_GAN: 3.098 G_L1: 16.026 D_real: 0.149 D_fake: 0.429 \n",
      "(epoch: 55, iters: 382, time: 0.103, data: 0.001) G_GAN: 3.432 G_L1: 18.482 D_real: 0.030 D_fake: 0.135 \n",
      "(epoch: 55, iters: 482, time: 0.104, data: 0.001) G_GAN: 4.026 G_L1: 11.103 D_real: 0.390 D_fake: 0.038 \n",
      "(epoch: 55, iters: 582, time: 0.484, data: 0.002) G_GAN: 2.846 G_L1: 14.636 D_real: 0.137 D_fake: 0.101 \n",
      "(epoch: 55, iters: 682, time: 0.103, data: 0.002) G_GAN: 2.783 G_L1: 16.137 D_real: 0.070 D_fake: 0.420 \n",
      "saving the model at the end of epoch 55, iters 42185\n",
      "End of epoch 55 / 200 \t Time Taken: 51 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 56, iters: 15, time: 0.102, data: 0.001) G_GAN: 3.244 G_L1: 6.806 D_real: 0.227 D_fake: 0.379 \n",
      "(epoch: 56, iters: 115, time: 0.077, data: 0.001) G_GAN: 3.853 G_L1: 18.851 D_real: 0.003 D_fake: 0.057 \n",
      "(epoch: 56, iters: 215, time: 0.483, data: 0.002) G_GAN: 2.206 G_L1: 6.654 D_real: 0.130 D_fake: 0.646 \n",
      "(epoch: 56, iters: 315, time: 0.104, data: 0.001) G_GAN: 3.363 G_L1: 7.503 D_real: 0.072 D_fake: 0.193 \n",
      "(epoch: 56, iters: 415, time: 0.104, data: 0.001) G_GAN: 3.213 G_L1: 14.097 D_real: 0.045 D_fake: 0.112 \n",
      "(epoch: 56, iters: 515, time: 0.105, data: 0.001) G_GAN: 4.074 G_L1: 13.179 D_real: 0.001 D_fake: 0.986 \n",
      "(epoch: 56, iters: 615, time: 0.210, data: 0.004) G_GAN: 1.140 G_L1: 10.926 D_real: 0.796 D_fake: 0.482 \n",
      "(epoch: 56, iters: 715, time: 0.103, data: 0.002) G_GAN: 2.986 G_L1: 10.593 D_real: 1.807 D_fake: 0.012 \n",
      "End of epoch 56 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 57, iters: 48, time: 0.104, data: 0.001) G_GAN: 2.766 G_L1: 7.614 D_real: 0.130 D_fake: 0.689 \n",
      "(epoch: 57, iters: 148, time: 0.104, data: 0.001) G_GAN: 2.545 G_L1: 20.040 D_real: 0.022 D_fake: 0.185 \n",
      "(epoch: 57, iters: 248, time: 0.521, data: 0.001) G_GAN: 2.362 G_L1: 8.265 D_real: 0.142 D_fake: 0.381 \n",
      "(epoch: 57, iters: 348, time: 0.103, data: 0.002) G_GAN: 1.839 G_L1: 11.302 D_real: 0.424 D_fake: 0.081 \n",
      "(epoch: 57, iters: 448, time: 0.103, data: 0.001) G_GAN: 3.159 G_L1: 17.930 D_real: 0.032 D_fake: 0.209 \n",
      "(epoch: 57, iters: 548, time: 0.105, data: 0.001) G_GAN: 3.775 G_L1: 12.498 D_real: 0.114 D_fake: 0.479 \n",
      "(epoch: 57, iters: 648, time: 0.217, data: 0.001) G_GAN: 2.184 G_L1: 26.585 D_real: 1.355 D_fake: 0.030 \n",
      "(epoch: 57, iters: 748, time: 0.105, data: 0.001) G_GAN: 2.669 G_L1: 10.384 D_real: 0.163 D_fake: 0.139 \n",
      "End of epoch 57 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 58, iters: 81, time: 0.105, data: 0.001) G_GAN: 3.513 G_L1: 11.340 D_real: 0.291 D_fake: 0.064 \n",
      "(epoch: 58, iters: 181, time: 0.104, data: 0.001) G_GAN: 2.806 G_L1: 12.097 D_real: 0.554 D_fake: 0.126 \n",
      "(epoch: 58, iters: 281, time: 0.491, data: 0.001) G_GAN: 1.745 G_L1: 8.129 D_real: 0.468 D_fake: 0.205 \n",
      "(epoch: 58, iters: 381, time: 0.106, data: 0.002) G_GAN: 2.870 G_L1: 13.066 D_real: 0.170 D_fake: 0.279 \n",
      "(epoch: 58, iters: 481, time: 0.103, data: 0.002) G_GAN: 1.914 G_L1: 12.778 D_real: 0.452 D_fake: 0.482 \n",
      "(epoch: 58, iters: 581, time: 0.103, data: 0.001) G_GAN: 3.200 G_L1: 20.067 D_real: 0.058 D_fake: 0.131 \n",
      "(epoch: 58, iters: 681, time: 0.201, data: 0.001) G_GAN: 2.096 G_L1: 13.221 D_real: 0.220 D_fake: 0.351 \n",
      "End of epoch 58 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 59, iters: 14, time: 0.106, data: 0.001) G_GAN: 3.676 G_L1: 15.821 D_real: 0.028 D_fake: 0.071 \n",
      "(epoch: 59, iters: 114, time: 0.105, data: 0.001) G_GAN: 3.483 G_L1: 13.995 D_real: 0.015 D_fake: 0.102 \n",
      "(epoch: 59, iters: 214, time: 0.105, data: 0.002) G_GAN: 2.313 G_L1: 12.275 D_real: 0.031 D_fake: 0.193 \n",
      "(epoch: 59, iters: 314, time: 0.455, data: 0.001) G_GAN: 3.045 G_L1: 8.639 D_real: 0.034 D_fake: 0.317 \n",
      "(epoch: 59, iters: 414, time: 0.102, data: 0.001) G_GAN: 3.439 G_L1: 12.852 D_real: 0.240 D_fake: 0.039 \n",
      "(epoch: 59, iters: 514, time: 0.103, data: 0.002) G_GAN: 4.803 G_L1: 30.685 D_real: 0.000 D_fake: 0.012 \n",
      "saving the latest model (epoch 59, total_iters 45000)\n",
      "(epoch: 59, iters: 614, time: 0.105, data: 0.002) G_GAN: 2.823 G_L1: 15.252 D_real: 0.408 D_fake: 0.025 \n",
      "(epoch: 59, iters: 714, time: 0.214, data: 0.001) G_GAN: 3.511 G_L1: 20.375 D_real: 0.028 D_fake: 0.104 \n",
      "End of epoch 59 / 200 \t Time Taken: 50 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 60, iters: 47, time: 0.105, data: 0.001) G_GAN: 2.445 G_L1: 11.808 D_real: 0.021 D_fake: 0.288 \n",
      "(epoch: 60, iters: 147, time: 0.103, data: 0.001) G_GAN: 2.377 G_L1: 10.405 D_real: 0.526 D_fake: 0.176 \n",
      "(epoch: 60, iters: 247, time: 0.103, data: 0.001) G_GAN: 2.803 G_L1: 8.505 D_real: 0.018 D_fake: 0.456 \n",
      "(epoch: 60, iters: 347, time: 0.489, data: 0.001) G_GAN: 2.260 G_L1: 5.765 D_real: 3.084 D_fake: 0.011 \n",
      "(epoch: 60, iters: 447, time: 0.105, data: 0.002) G_GAN: 2.216 G_L1: 12.145 D_real: 0.152 D_fake: 0.124 \n",
      "(epoch: 60, iters: 547, time: 0.103, data: 0.001) G_GAN: 3.975 G_L1: 12.994 D_real: 0.112 D_fake: 0.028 \n",
      "(epoch: 60, iters: 647, time: 0.104, data: 0.001) G_GAN: 2.717 G_L1: 12.596 D_real: 0.020 D_fake: 0.185 \n",
      "(epoch: 60, iters: 747, time: 0.507, data: 0.001) G_GAN: 1.412 G_L1: 7.067 D_real: 0.662 D_fake: 0.462 \n",
      "saving the model at the end of epoch 60, iters 46020\n",
      "End of epoch 60 / 200 \t Time Taken: 51 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 61, iters: 80, time: 0.095, data: 0.002) G_GAN: 5.982 G_L1: 11.393 D_real: 0.027 D_fake: 0.005 \n",
      "(epoch: 61, iters: 180, time: 0.104, data: 0.002) G_GAN: 3.577 G_L1: 24.454 D_real: 0.019 D_fake: 0.094 \n",
      "(epoch: 61, iters: 280, time: 0.106, data: 0.001) G_GAN: 2.490 G_L1: 13.001 D_real: 0.038 D_fake: 0.232 \n",
      "(epoch: 61, iters: 380, time: 0.495, data: 0.002) G_GAN: 3.156 G_L1: 20.907 D_real: 0.057 D_fake: 0.050 \n",
      "(epoch: 61, iters: 480, time: 0.104, data: 0.001) G_GAN: 1.134 G_L1: 12.624 D_real: 2.373 D_fake: 0.102 \n",
      "(epoch: 61, iters: 580, time: 0.104, data: 0.001) G_GAN: 2.311 G_L1: 10.277 D_real: 0.033 D_fake: 0.733 \n",
      "(epoch: 61, iters: 680, time: 0.105, data: 0.002) G_GAN: 3.543 G_L1: 9.554 D_real: 0.009 D_fake: 0.057 \n",
      "End of epoch 61 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 62, iters: 13, time: 0.513, data: 0.002) G_GAN: 1.010 G_L1: 8.334 D_real: 0.870 D_fake: 0.123 \n",
      "(epoch: 62, iters: 113, time: 0.105, data: 0.002) G_GAN: 4.030 G_L1: 22.608 D_real: 1.941 D_fake: 0.005 \n",
      "(epoch: 62, iters: 213, time: 0.104, data: 0.001) G_GAN: 5.444 G_L1: 17.940 D_real: 0.004 D_fake: 0.014 \n",
      "(epoch: 62, iters: 313, time: 0.106, data: 0.001) G_GAN: 1.588 G_L1: 5.565 D_real: 0.542 D_fake: 0.136 \n",
      "(epoch: 62, iters: 413, time: 0.215, data: 0.002) G_GAN: 3.571 G_L1: 17.934 D_real: 0.036 D_fake: 0.050 \n",
      "(epoch: 62, iters: 513, time: 0.104, data: 0.001) G_GAN: 2.634 G_L1: 12.136 D_real: 0.013 D_fake: 0.335 \n",
      "(epoch: 62, iters: 613, time: 0.098, data: 0.001) G_GAN: 0.333 G_L1: 11.182 D_real: 1.660 D_fake: 0.050 \n",
      "(epoch: 62, iters: 713, time: 0.104, data: 0.001) G_GAN: 2.238 G_L1: 6.809 D_real: 0.128 D_fake: 0.991 \n",
      "End of epoch 62 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 63, iters: 46, time: 0.503, data: 0.001) G_GAN: 2.757 G_L1: 12.662 D_real: 0.281 D_fake: 0.213 \n",
      "(epoch: 63, iters: 146, time: 0.105, data: 0.002) G_GAN: 2.297 G_L1: 13.831 D_real: 0.310 D_fake: 0.504 \n",
      "(epoch: 63, iters: 246, time: 0.104, data: 0.001) G_GAN: 3.098 G_L1: 20.651 D_real: 0.000 D_fake: 0.291 \n",
      "(epoch: 63, iters: 346, time: 0.103, data: 0.001) G_GAN: 3.389 G_L1: 11.683 D_real: 0.105 D_fake: 0.042 \n",
      "(epoch: 63, iters: 446, time: 0.480, data: 0.001) G_GAN: 4.304 G_L1: 16.910 D_real: 0.930 D_fake: 0.011 \n",
      "(epoch: 63, iters: 546, time: 0.102, data: 0.001) G_GAN: 2.173 G_L1: 16.278 D_real: 0.196 D_fake: 0.258 \n",
      "(epoch: 63, iters: 646, time: 0.102, data: 0.001) G_GAN: 3.453 G_L1: 13.639 D_real: 0.105 D_fake: 0.220 \n",
      "(epoch: 63, iters: 746, time: 0.100, data: 0.002) G_GAN: 3.975 G_L1: 16.409 D_real: 0.010 D_fake: 0.657 \n",
      "End of epoch 63 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 64, iters: 79, time: 0.490, data: 0.002) G_GAN: 2.707 G_L1: 15.991 D_real: 0.422 D_fake: 0.274 \n",
      "(epoch: 64, iters: 179, time: 0.106, data: 0.001) G_GAN: 2.992 G_L1: 8.183 D_real: 0.053 D_fake: 0.391 \n",
      "(epoch: 64, iters: 279, time: 0.105, data: 0.001) G_GAN: 3.353 G_L1: 18.406 D_real: 0.019 D_fake: 0.064 \n",
      "(epoch: 64, iters: 379, time: 0.104, data: 0.001) G_GAN: 4.355 G_L1: 15.429 D_real: 0.058 D_fake: 0.076 \n",
      "(epoch: 64, iters: 479, time: 0.218, data: 0.001) G_GAN: 1.203 G_L1: 6.782 D_real: 0.303 D_fake: 0.562 \n",
      "(epoch: 64, iters: 579, time: 0.105, data: 0.002) G_GAN: 3.193 G_L1: 13.990 D_real: 0.696 D_fake: 0.486 \n",
      "(epoch: 64, iters: 679, time: 0.105, data: 0.001) G_GAN: 3.482 G_L1: 18.386 D_real: 0.234 D_fake: 0.134 \n",
      "End of epoch 64 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 65, iters: 12, time: 0.103, data: 0.001) G_GAN: 4.324 G_L1: 7.607 D_real: 0.150 D_fake: 1.655 \n",
      "(epoch: 65, iters: 112, time: 0.493, data: 0.002) G_GAN: 2.387 G_L1: 9.662 D_real: 0.243 D_fake: 0.219 \n",
      "(epoch: 65, iters: 212, time: 0.106, data: 0.002) G_GAN: 3.070 G_L1: 22.480 D_real: 0.000 D_fake: 0.135 \n",
      "(epoch: 65, iters: 312, time: 0.103, data: 0.001) G_GAN: 2.799 G_L1: 8.961 D_real: 0.087 D_fake: 0.560 \n",
      "(epoch: 65, iters: 412, time: 0.104, data: 0.001) G_GAN: 2.819 G_L1: 17.426 D_real: 0.130 D_fake: 0.500 \n",
      "(epoch: 65, iters: 512, time: 0.227, data: 0.001) G_GAN: 2.482 G_L1: 14.836 D_real: 0.018 D_fake: 1.253 \n",
      "(epoch: 65, iters: 612, time: 0.105, data: 0.001) G_GAN: 2.223 G_L1: 9.290 D_real: 0.316 D_fake: 0.389 \n",
      "(epoch: 65, iters: 712, time: 0.106, data: 0.001) G_GAN: 2.826 G_L1: 18.827 D_real: 0.010 D_fake: 0.282 \n",
      "saving the model at the end of epoch 65, iters 49855\n",
      "End of epoch 65 / 200 \t Time Taken: 51 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 66, iters: 45, time: 0.103, data: 0.001) G_GAN: 3.314 G_L1: 9.936 D_real: 0.005 D_fake: 0.208 \n",
      "(epoch: 66, iters: 145, time: 0.560, data: 0.001) G_GAN: 2.992 G_L1: 9.505 D_real: 0.078 D_fake: 0.403 \n",
      "saving the latest model (epoch 66, total_iters 50000)\n",
      "(epoch: 66, iters: 245, time: 0.104, data: 0.002) G_GAN: 4.091 G_L1: 13.632 D_real: 0.006 D_fake: 1.667 \n",
      "(epoch: 66, iters: 345, time: 0.103, data: 0.001) G_GAN: 1.357 G_L1: 10.632 D_real: 0.968 D_fake: 0.124 \n",
      "(epoch: 66, iters: 445, time: 0.105, data: 0.001) G_GAN: 2.167 G_L1: 17.052 D_real: 0.381 D_fake: 0.053 \n",
      "(epoch: 66, iters: 545, time: 0.215, data: 0.001) G_GAN: 4.165 G_L1: 16.332 D_real: 0.064 D_fake: 0.036 \n",
      "(epoch: 66, iters: 645, time: 0.103, data: 0.002) G_GAN: 2.898 G_L1: 5.230 D_real: 0.087 D_fake: 0.202 \n",
      "(epoch: 66, iters: 745, time: 0.105, data: 0.001) G_GAN: 2.369 G_L1: 14.732 D_real: 0.276 D_fake: 0.467 \n",
      "End of epoch 66 / 200 \t Time Taken: 50 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 67, iters: 78, time: 0.104, data: 0.001) G_GAN: 3.482 G_L1: 11.007 D_real: 0.014 D_fake: 0.210 \n",
      "(epoch: 67, iters: 178, time: 0.589, data: 0.001) G_GAN: 1.188 G_L1: 5.584 D_real: 0.339 D_fake: 0.415 \n",
      "(epoch: 67, iters: 278, time: 0.105, data: 0.001) G_GAN: 3.847 G_L1: 11.254 D_real: 0.011 D_fake: 0.032 \n",
      "(epoch: 67, iters: 378, time: 0.104, data: 0.001) G_GAN: 1.295 G_L1: 7.848 D_real: 0.853 D_fake: 0.088 \n",
      "(epoch: 67, iters: 478, time: 0.104, data: 0.001) G_GAN: 3.805 G_L1: 9.191 D_real: 1.186 D_fake: 0.006 \n",
      "(epoch: 67, iters: 578, time: 0.203, data: 0.001) G_GAN: 4.864 G_L1: 20.143 D_real: 0.067 D_fake: 0.014 \n",
      "(epoch: 67, iters: 678, time: 0.105, data: 0.002) G_GAN: 3.188 G_L1: 16.548 D_real: 0.123 D_fake: 0.054 \n",
      "End of epoch 67 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 68, iters: 11, time: 0.103, data: 0.001) G_GAN: 3.929 G_L1: 14.340 D_real: 0.041 D_fake: 0.066 \n",
      "(epoch: 68, iters: 111, time: 0.104, data: 0.002) G_GAN: 2.767 G_L1: 8.923 D_real: 0.995 D_fake: 0.018 \n",
      "(epoch: 68, iters: 211, time: 0.505, data: 0.002) G_GAN: 3.325 G_L1: 12.315 D_real: 0.011 D_fake: 0.037 \n",
      "(epoch: 68, iters: 311, time: 0.105, data: 0.002) G_GAN: 3.391 G_L1: 11.700 D_real: 0.122 D_fake: 0.073 \n",
      "(epoch: 68, iters: 411, time: 0.103, data: 0.001) G_GAN: 2.437 G_L1: 9.388 D_real: 0.070 D_fake: 0.592 \n",
      "(epoch: 68, iters: 511, time: 0.104, data: 0.001) G_GAN: 2.704 G_L1: 10.604 D_real: 0.087 D_fake: 2.090 \n",
      "(epoch: 68, iters: 611, time: 0.514, data: 0.001) G_GAN: 1.945 G_L1: 10.796 D_real: 0.365 D_fake: 0.079 \n",
      "(epoch: 68, iters: 711, time: 0.101, data: 0.001) G_GAN: 3.831 G_L1: 5.577 D_real: 0.016 D_fake: 0.060 \n",
      "End of epoch 68 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 69, iters: 44, time: 0.105, data: 0.001) G_GAN: 2.871 G_L1: 10.765 D_real: 0.298 D_fake: 0.066 \n",
      "(epoch: 69, iters: 144, time: 0.104, data: 0.001) G_GAN: 1.301 G_L1: 6.258 D_real: 0.933 D_fake: 0.434 \n",
      "(epoch: 69, iters: 244, time: 0.502, data: 0.002) G_GAN: 1.461 G_L1: 11.490 D_real: 0.596 D_fake: 0.185 \n",
      "(epoch: 69, iters: 344, time: 0.102, data: 0.002) G_GAN: 1.714 G_L1: 6.353 D_real: 0.401 D_fake: 0.294 \n",
      "(epoch: 69, iters: 444, time: 0.104, data: 0.002) G_GAN: 1.677 G_L1: 10.460 D_real: 0.321 D_fake: 0.194 \n",
      "(epoch: 69, iters: 544, time: 0.105, data: 0.002) G_GAN: 4.708 G_L1: 7.635 D_real: 0.000 D_fake: 0.883 \n",
      "(epoch: 69, iters: 644, time: 0.208, data: 0.001) G_GAN: 2.354 G_L1: 10.630 D_real: 0.001 D_fake: 1.030 \n",
      "(epoch: 69, iters: 744, time: 0.104, data: 0.002) G_GAN: 1.563 G_L1: 18.827 D_real: 0.727 D_fake: 0.400 \n",
      "End of epoch 69 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 70, iters: 77, time: 0.104, data: 0.002) G_GAN: 2.339 G_L1: 12.029 D_real: 0.060 D_fake: 0.290 \n",
      "(epoch: 70, iters: 177, time: 0.103, data: 0.001) G_GAN: 5.253 G_L1: 10.346 D_real: 0.001 D_fake: 0.016 \n",
      "(epoch: 70, iters: 277, time: 0.506, data: 0.001) G_GAN: 1.642 G_L1: 8.538 D_real: 0.421 D_fake: 0.246 \n",
      "(epoch: 70, iters: 377, time: 0.104, data: 0.001) G_GAN: 3.318 G_L1: 9.075 D_real: 0.002 D_fake: 0.100 \n",
      "(epoch: 70, iters: 477, time: 0.104, data: 0.001) G_GAN: 2.516 G_L1: 10.315 D_real: 0.001 D_fake: 0.448 \n",
      "(epoch: 70, iters: 577, time: 0.105, data: 0.001) G_GAN: 2.892 G_L1: 17.597 D_real: 0.001 D_fake: 0.931 \n",
      "(epoch: 70, iters: 677, time: 0.215, data: 0.002) G_GAN: 3.254 G_L1: 14.438 D_real: 0.000 D_fake: 0.254 \n",
      "saving the model at the end of epoch 70, iters 53690\n",
      "End of epoch 70 / 200 \t Time Taken: 51 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 71, iters: 10, time: 0.103, data: 0.001) G_GAN: 5.335 G_L1: 12.212 D_real: 0.201 D_fake: 0.008 \n",
      "(epoch: 71, iters: 110, time: 0.104, data: 0.001) G_GAN: 1.827 G_L1: 10.073 D_real: 0.451 D_fake: 0.175 \n",
      "(epoch: 71, iters: 210, time: 0.105, data: 0.001) G_GAN: 3.107 G_L1: 9.542 D_real: 0.010 D_fake: 0.622 \n",
      "(epoch: 71, iters: 310, time: 0.491, data: 0.001) G_GAN: 2.859 G_L1: 8.164 D_real: 0.417 D_fake: 0.049 \n",
      "(epoch: 71, iters: 410, time: 0.103, data: 0.001) G_GAN: 2.664 G_L1: 16.964 D_real: 0.257 D_fake: 0.126 \n",
      "(epoch: 71, iters: 510, time: 0.106, data: 0.002) G_GAN: 3.101 G_L1: 16.697 D_real: 0.098 D_fake: 0.135 \n",
      "(epoch: 71, iters: 610, time: 0.104, data: 0.001) G_GAN: 3.560 G_L1: 8.866 D_real: 0.091 D_fake: 0.036 \n",
      "(epoch: 71, iters: 710, time: 0.216, data: 0.001) G_GAN: 1.992 G_L1: 9.155 D_real: 0.469 D_fake: 0.137 \n",
      "End of epoch 71 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 72, iters: 43, time: 0.103, data: 0.001) G_GAN: 4.447 G_L1: 13.955 D_real: 0.000 D_fake: 0.021 \n",
      "(epoch: 72, iters: 143, time: 0.104, data: 0.001) G_GAN: 2.854 G_L1: 7.968 D_real: 0.159 D_fake: 0.134 \n",
      "(epoch: 72, iters: 243, time: 0.105, data: 0.002) G_GAN: 4.013 G_L1: 14.615 D_real: 0.000 D_fake: 0.050 \n",
      "(epoch: 72, iters: 343, time: 0.516, data: 0.001) G_GAN: 3.018 G_L1: 9.021 D_real: 0.001 D_fake: 0.489 \n",
      "(epoch: 72, iters: 443, time: 0.106, data: 0.001) G_GAN: 2.903 G_L1: 8.864 D_real: 0.039 D_fake: 1.422 \n",
      "(epoch: 72, iters: 543, time: 0.103, data: 0.001) G_GAN: 2.484 G_L1: 8.886 D_real: 0.331 D_fake: 1.068 \n",
      "saving the latest model (epoch 72, total_iters 55000)\n",
      "(epoch: 72, iters: 643, time: 0.093, data: 0.001) G_GAN: 3.488 G_L1: 17.026 D_real: 0.040 D_fake: 0.086 \n",
      "(epoch: 72, iters: 743, time: 0.202, data: 0.002) G_GAN: 3.017 G_L1: 13.144 D_real: 0.039 D_fake: 0.062 \n",
      "End of epoch 72 / 200 \t Time Taken: 50 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 73, iters: 76, time: 0.102, data: 0.001) G_GAN: 4.198 G_L1: 6.859 D_real: 0.053 D_fake: 1.326 \n",
      "(epoch: 73, iters: 176, time: 0.106, data: 0.001) G_GAN: 2.604 G_L1: 14.703 D_real: 0.029 D_fake: 0.331 \n",
      "(epoch: 73, iters: 276, time: 0.105, data: 0.001) G_GAN: 2.096 G_L1: 17.272 D_real: 0.880 D_fake: 0.092 \n",
      "(epoch: 73, iters: 376, time: 0.483, data: 0.001) G_GAN: 2.419 G_L1: 16.232 D_real: 0.085 D_fake: 0.398 \n",
      "(epoch: 73, iters: 476, time: 0.104, data: 0.002) G_GAN: 3.918 G_L1: 12.920 D_real: 0.003 D_fake: 0.042 \n",
      "(epoch: 73, iters: 576, time: 0.104, data: 0.002) G_GAN: 3.341 G_L1: 14.984 D_real: 0.145 D_fake: 0.053 \n",
      "(epoch: 73, iters: 676, time: 0.104, data: 0.001) G_GAN: 1.940 G_L1: 11.779 D_real: 1.110 D_fake: 0.053 \n",
      "End of epoch 73 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 74, iters: 9, time: 0.537, data: 0.001) G_GAN: 5.407 G_L1: 8.895 D_real: 0.006 D_fake: 0.014 \n",
      "(epoch: 74, iters: 109, time: 0.103, data: 0.002) G_GAN: 2.416 G_L1: 15.380 D_real: 0.019 D_fake: 0.865 \n",
      "(epoch: 74, iters: 209, time: 0.103, data: 0.001) G_GAN: 0.668 G_L1: 7.130 D_real: 1.211 D_fake: 0.258 \n",
      "(epoch: 74, iters: 309, time: 0.101, data: 0.002) G_GAN: 2.360 G_L1: 11.076 D_real: 0.001 D_fake: 0.208 \n",
      "(epoch: 74, iters: 409, time: 0.214, data: 0.001) G_GAN: 3.045 G_L1: 10.289 D_real: 0.001 D_fake: 0.103 \n",
      "(epoch: 74, iters: 509, time: 0.106, data: 0.002) G_GAN: 2.196 G_L1: 15.128 D_real: 0.496 D_fake: 0.143 \n",
      "(epoch: 74, iters: 609, time: 0.105, data: 0.001) G_GAN: 5.211 G_L1: 16.003 D_real: 0.003 D_fake: 0.012 \n",
      "(epoch: 74, iters: 709, time: 0.104, data: 0.001) G_GAN: 3.194 G_L1: 13.409 D_real: 0.001 D_fake: 0.169 \n",
      "End of epoch 74 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 75, iters: 42, time: 0.514, data: 0.001) G_GAN: 2.977 G_L1: 16.799 D_real: 0.251 D_fake: 0.093 \n",
      "(epoch: 75, iters: 142, time: 0.103, data: 0.002) G_GAN: 2.873 G_L1: 10.190 D_real: 0.904 D_fake: 0.035 \n",
      "(epoch: 75, iters: 242, time: 0.103, data: 0.001) G_GAN: 0.980 G_L1: 12.775 D_real: 1.412 D_fake: 0.322 \n",
      "(epoch: 75, iters: 342, time: 0.104, data: 0.001) G_GAN: 4.887 G_L1: 9.157 D_real: 0.002 D_fake: 0.013 \n",
      "(epoch: 75, iters: 442, time: 0.216, data: 0.001) G_GAN: 1.787 G_L1: 6.789 D_real: 0.282 D_fake: 0.500 \n",
      "(epoch: 75, iters: 542, time: 0.105, data: 0.001) G_GAN: 3.751 G_L1: 7.233 D_real: 0.000 D_fake: 0.272 \n",
      "(epoch: 75, iters: 642, time: 0.103, data: 0.001) G_GAN: 2.032 G_L1: 7.269 D_real: 1.994 D_fake: 0.029 \n",
      "(epoch: 75, iters: 742, time: 0.105, data: 0.001) G_GAN: 3.730 G_L1: 6.534 D_real: 0.003 D_fake: 0.065 \n",
      "saving the model at the end of epoch 75, iters 57525\n",
      "End of epoch 75 / 200 \t Time Taken: 51 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 76, iters: 75, time: 0.725, data: 0.001) G_GAN: 1.130 G_L1: 8.694 D_real: 0.935 D_fake: 0.219 \n",
      "(epoch: 76, iters: 175, time: 0.104, data: 0.003) G_GAN: 2.714 G_L1: 10.326 D_real: 0.391 D_fake: 0.088 \n",
      "(epoch: 76, iters: 275, time: 0.104, data: 0.001) G_GAN: 1.468 G_L1: 15.289 D_real: 1.608 D_fake: 0.091 \n",
      "(epoch: 76, iters: 375, time: 0.106, data: 0.002) G_GAN: 3.428 G_L1: 15.466 D_real: 0.018 D_fake: 0.755 \n",
      "(epoch: 76, iters: 475, time: 0.524, data: 0.001) G_GAN: 1.794 G_L1: 11.259 D_real: 0.540 D_fake: 0.233 \n",
      "(epoch: 76, iters: 575, time: 0.103, data: 0.001) G_GAN: 1.326 G_L1: 12.418 D_real: 2.744 D_fake: 0.015 \n",
      "(epoch: 76, iters: 675, time: 0.106, data: 0.001) G_GAN: 4.100 G_L1: 10.113 D_real: 0.087 D_fake: 0.059 \n",
      "End of epoch 76 / 200 \t Time Taken: 50 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 77, iters: 8, time: 0.105, data: 0.001) G_GAN: 4.276 G_L1: 14.482 D_real: 0.086 D_fake: 0.024 \n",
      "(epoch: 77, iters: 108, time: 0.528, data: 0.003) G_GAN: 3.302 G_L1: 14.149 D_real: 0.048 D_fake: 0.576 \n",
      "(epoch: 77, iters: 208, time: 0.103, data: 0.002) G_GAN: 2.889 G_L1: 12.500 D_real: 0.000 D_fake: 0.199 \n",
      "(epoch: 77, iters: 308, time: 0.104, data: 0.001) G_GAN: 1.945 G_L1: 13.962 D_real: 0.422 D_fake: 0.307 \n",
      "(epoch: 77, iters: 408, time: 0.106, data: 0.001) G_GAN: 4.860 G_L1: 8.237 D_real: 0.026 D_fake: 0.018 \n",
      "(epoch: 77, iters: 508, time: 0.206, data: 0.002) G_GAN: 3.246 G_L1: 10.524 D_real: 0.180 D_fake: 0.032 \n",
      "(epoch: 77, iters: 608, time: 0.103, data: 0.001) G_GAN: 2.090 G_L1: 8.467 D_real: 0.234 D_fake: 0.757 \n",
      "(epoch: 77, iters: 708, time: 0.105, data: 0.001) G_GAN: 4.039 G_L1: 6.171 D_real: 0.002 D_fake: 0.043 \n",
      "End of epoch 77 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 78, iters: 41, time: 0.104, data: 0.001) G_GAN: 1.457 G_L1: 7.947 D_real: 0.848 D_fake: 0.077 \n",
      "(epoch: 78, iters: 141, time: 0.538, data: 0.001) G_GAN: 2.994 G_L1: 15.212 D_real: 0.010 D_fake: 0.284 \n",
      "(epoch: 78, iters: 241, time: 0.097, data: 0.001) G_GAN: 1.084 G_L1: 7.009 D_real: 2.560 D_fake: 0.064 \n",
      "(epoch: 78, iters: 341, time: 0.105, data: 0.001) G_GAN: 1.950 G_L1: 6.631 D_real: 0.490 D_fake: 0.054 \n",
      "(epoch: 78, iters: 441, time: 0.106, data: 0.001) G_GAN: 3.336 G_L1: 21.161 D_real: 0.040 D_fake: 0.081 \n",
      "(epoch: 78, iters: 541, time: 0.225, data: 0.001) G_GAN: 2.270 G_L1: 13.793 D_real: 0.000 D_fake: 0.380 \n",
      "(epoch: 78, iters: 641, time: 0.104, data: 0.002) G_GAN: 4.195 G_L1: 13.971 D_real: 0.000 D_fake: 0.044 \n",
      "(epoch: 78, iters: 741, time: 0.103, data: 0.002) G_GAN: 2.862 G_L1: 8.999 D_real: 0.000 D_fake: 0.451 \n",
      "End of epoch 78 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 79, iters: 74, time: 0.103, data: 0.001) G_GAN: 2.959 G_L1: 17.506 D_real: 0.002 D_fake: 0.486 \n",
      "(epoch: 79, iters: 174, time: 0.512, data: 0.001) G_GAN: 2.786 G_L1: 12.041 D_real: 0.005 D_fake: 0.387 \n",
      "saving the latest model (epoch 79, total_iters 60000)\n",
      "(epoch: 79, iters: 274, time: 0.105, data: 0.002) G_GAN: 4.442 G_L1: 12.175 D_real: 0.001 D_fake: 0.087 \n",
      "(epoch: 79, iters: 374, time: 0.104, data: 0.001) G_GAN: 1.766 G_L1: 5.815 D_real: 0.394 D_fake: 0.192 \n",
      "(epoch: 79, iters: 474, time: 0.104, data: 0.001) G_GAN: 1.989 G_L1: 14.056 D_real: 0.312 D_fake: 0.089 \n",
      "(epoch: 79, iters: 574, time: 0.215, data: 0.001) G_GAN: 2.444 G_L1: 10.270 D_real: 0.457 D_fake: 0.082 \n",
      "(epoch: 79, iters: 674, time: 0.104, data: 0.001) G_GAN: 2.441 G_L1: 17.660 D_real: 0.256 D_fake: 0.360 \n",
      "End of epoch 79 / 200 \t Time Taken: 50 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 80, iters: 7, time: 0.103, data: 0.001) G_GAN: 3.743 G_L1: 12.968 D_real: 0.041 D_fake: 0.817 \n",
      "(epoch: 80, iters: 107, time: 0.104, data: 0.000) G_GAN: 2.923 G_L1: 17.182 D_real: 0.006 D_fake: 1.020 \n",
      "(epoch: 80, iters: 207, time: 0.528, data: 0.001) G_GAN: 1.130 G_L1: 12.122 D_real: 0.469 D_fake: 0.134 \n",
      "(epoch: 80, iters: 307, time: 0.103, data: 0.001) G_GAN: 5.493 G_L1: 14.502 D_real: 0.002 D_fake: 0.014 \n",
      "(epoch: 80, iters: 407, time: 0.104, data: 0.002) G_GAN: 0.827 G_L1: 6.917 D_real: 0.606 D_fake: 0.329 \n",
      "(epoch: 80, iters: 507, time: 0.105, data: 0.001) G_GAN: 5.056 G_L1: 15.583 D_real: 0.275 D_fake: 0.005 \n",
      "(epoch: 80, iters: 607, time: 0.210, data: 0.002) G_GAN: 4.264 G_L1: 10.404 D_real: 0.071 D_fake: 2.412 \n",
      "(epoch: 80, iters: 707, time: 0.105, data: 0.001) G_GAN: 3.968 G_L1: 18.763 D_real: 0.001 D_fake: 0.038 \n",
      "saving the model at the end of epoch 80, iters 61360\n",
      "End of epoch 80 / 200 \t Time Taken: 51 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 81, iters: 40, time: 0.104, data: 0.001) G_GAN: 1.836 G_L1: 8.556 D_real: 0.449 D_fake: 0.129 \n",
      "(epoch: 81, iters: 140, time: 0.096, data: 0.002) G_GAN: 3.489 G_L1: 11.788 D_real: 0.062 D_fake: 0.081 \n",
      "(epoch: 81, iters: 240, time: 0.533, data: 0.002) G_GAN: 2.344 G_L1: 9.834 D_real: 1.525 D_fake: 0.018 \n",
      "(epoch: 81, iters: 340, time: 0.104, data: 0.002) G_GAN: 3.704 G_L1: 17.580 D_real: 0.003 D_fake: 0.152 \n",
      "(epoch: 81, iters: 440, time: 0.104, data: 0.001) G_GAN: 0.763 G_L1: 9.398 D_real: 0.722 D_fake: 0.145 \n",
      "(epoch: 81, iters: 540, time: 0.105, data: 0.001) G_GAN: 2.706 G_L1: 13.923 D_real: 0.126 D_fake: 0.906 \n",
      "(epoch: 81, iters: 640, time: 0.520, data: 0.001) G_GAN: 3.209 G_L1: 12.728 D_real: 0.001 D_fake: 0.161 \n",
      "(epoch: 81, iters: 740, time: 0.106, data: 0.002) G_GAN: 2.114 G_L1: 5.626 D_real: 0.305 D_fake: 0.807 \n",
      "End of epoch 81 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 82, iters: 73, time: 0.103, data: 0.001) G_GAN: 4.246 G_L1: 14.156 D_real: 0.012 D_fake: 0.034 \n",
      "(epoch: 82, iters: 173, time: 0.103, data: 0.001) G_GAN: 1.784 G_L1: 10.892 D_real: 0.991 D_fake: 0.044 \n",
      "(epoch: 82, iters: 273, time: 0.550, data: 0.001) G_GAN: 4.238 G_L1: 16.862 D_real: 0.031 D_fake: 0.039 \n",
      "(epoch: 82, iters: 373, time: 0.105, data: 0.002) G_GAN: 0.074 G_L1: 10.662 D_real: 2.566 D_fake: 0.033 \n",
      "(epoch: 82, iters: 473, time: 0.104, data: 0.001) G_GAN: 3.514 G_L1: 8.564 D_real: 0.008 D_fake: 0.548 \n",
      "(epoch: 82, iters: 573, time: 0.104, data: 0.001) G_GAN: 5.340 G_L1: 12.690 D_real: 0.166 D_fake: 1.232 \n",
      "(epoch: 82, iters: 673, time: 0.215, data: 0.002) G_GAN: 1.758 G_L1: 16.846 D_real: 0.609 D_fake: 0.070 \n",
      "End of epoch 82 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 83, iters: 6, time: 0.091, data: 0.001) G_GAN: 3.029 G_L1: 9.152 D_real: 0.181 D_fake: 0.585 \n",
      "(epoch: 83, iters: 106, time: 0.105, data: 0.000) G_GAN: 3.551 G_L1: 12.869 D_real: 0.333 D_fake: 0.076 \n",
      "(epoch: 83, iters: 206, time: 0.104, data: 0.001) G_GAN: 3.241 G_L1: 7.528 D_real: 0.053 D_fake: 0.585 \n",
      "(epoch: 83, iters: 306, time: 0.595, data: 0.001) G_GAN: 2.128 G_L1: 8.016 D_real: 0.308 D_fake: 0.104 \n",
      "(epoch: 83, iters: 406, time: 0.104, data: 0.001) G_GAN: 2.211 G_L1: 22.133 D_real: 0.189 D_fake: 0.367 \n",
      "(epoch: 83, iters: 506, time: 0.105, data: 0.002) G_GAN: 4.911 G_L1: 11.566 D_real: 0.022 D_fake: 0.859 \n",
      "(epoch: 83, iters: 606, time: 0.103, data: 0.001) G_GAN: 3.158 G_L1: 11.933 D_real: 0.094 D_fake: 0.259 \n",
      "(epoch: 83, iters: 706, time: 0.223, data: 0.001) G_GAN: 3.012 G_L1: 11.096 D_real: 0.004 D_fake: 0.277 \n",
      "End of epoch 83 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 84, iters: 39, time: 0.105, data: 0.002) G_GAN: 2.869 G_L1: 6.652 D_real: 0.090 D_fake: 0.189 \n",
      "(epoch: 84, iters: 139, time: 0.104, data: 0.001) G_GAN: 2.595 G_L1: 5.678 D_real: 0.179 D_fake: 0.301 \n",
      "(epoch: 84, iters: 239, time: 0.103, data: 0.002) G_GAN: 5.867 G_L1: 7.068 D_real: 0.019 D_fake: 1.900 \n",
      "(epoch: 84, iters: 339, time: 0.521, data: 0.001) G_GAN: 2.619 G_L1: 13.927 D_real: 0.014 D_fake: 0.552 \n",
      "(epoch: 84, iters: 439, time: 0.105, data: 0.001) G_GAN: 2.704 G_L1: 10.818 D_real: 0.032 D_fake: 0.257 \n",
      "(epoch: 84, iters: 539, time: 0.104, data: 0.001) G_GAN: 3.210 G_L1: 15.214 D_real: 0.155 D_fake: 0.063 \n",
      "(epoch: 84, iters: 639, time: 0.105, data: 0.001) G_GAN: 3.033 G_L1: 14.862 D_real: 0.012 D_fake: 0.285 \n",
      "(epoch: 84, iters: 739, time: 0.211, data: 0.001) G_GAN: 1.361 G_L1: 8.441 D_real: 0.463 D_fake: 0.073 \n",
      "End of epoch 84 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 85, iters: 72, time: 0.105, data: 0.002) G_GAN: 2.237 G_L1: 9.954 D_real: 0.445 D_fake: 0.153 \n",
      "(epoch: 85, iters: 172, time: 0.105, data: 0.001) G_GAN: 3.853 G_L1: 10.926 D_real: 0.000 D_fake: 0.088 \n",
      "(epoch: 85, iters: 272, time: 0.105, data: 0.001) G_GAN: 0.652 G_L1: 7.097 D_real: 0.558 D_fake: 0.268 \n",
      "(epoch: 85, iters: 372, time: 0.561, data: 0.002) G_GAN: 0.608 G_L1: 6.707 D_real: 1.297 D_fake: 0.057 \n",
      "(epoch: 85, iters: 472, time: 0.105, data: 0.002) G_GAN: 2.673 G_L1: 11.372 D_real: 0.248 D_fake: 0.061 \n",
      "(epoch: 85, iters: 572, time: 0.101, data: 0.001) G_GAN: 3.079 G_L1: 10.658 D_real: 0.011 D_fake: 0.122 \n",
      "saving the latest model (epoch 85, total_iters 65000)\n",
      "(epoch: 85, iters: 672, time: 0.104, data: 0.002) G_GAN: 1.895 G_L1: 6.637 D_real: 0.254 D_fake: 0.341 \n",
      "saving the model at the end of epoch 85, iters 65195\n",
      "End of epoch 85 / 200 \t Time Taken: 52 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 86, iters: 5, time: 0.553, data: 0.001) G_GAN: 2.459 G_L1: 9.638 D_real: 0.352 D_fake: 0.130 \n",
      "(epoch: 86, iters: 105, time: 0.105, data: 0.004) G_GAN: 2.087 G_L1: 5.052 D_real: 0.261 D_fake: 0.544 \n",
      "(epoch: 86, iters: 205, time: 0.078, data: 0.001) G_GAN: 1.231 G_L1: 7.564 D_real: 0.818 D_fake: 0.116 \n",
      "(epoch: 86, iters: 305, time: 0.105, data: 0.001) G_GAN: 4.656 G_L1: 7.024 D_real: 0.012 D_fake: 1.615 \n",
      "(epoch: 86, iters: 405, time: 0.222, data: 0.001) G_GAN: 3.485 G_L1: 11.347 D_real: 0.165 D_fake: 0.058 \n",
      "(epoch: 86, iters: 505, time: 0.105, data: 0.001) G_GAN: 4.044 G_L1: 12.729 D_real: 0.057 D_fake: 0.045 \n",
      "(epoch: 86, iters: 605, time: 0.105, data: 0.002) G_GAN: 2.014 G_L1: 6.856 D_real: 0.382 D_fake: 0.097 \n",
      "(epoch: 86, iters: 705, time: 0.104, data: 0.001) G_GAN: 3.318 G_L1: 13.503 D_real: 0.379 D_fake: 0.026 \n",
      "End of epoch 86 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 87, iters: 38, time: 0.552, data: 0.001) G_GAN: 2.450 G_L1: 6.959 D_real: 0.216 D_fake: 0.431 \n",
      "(epoch: 87, iters: 138, time: 0.105, data: 0.001) G_GAN: 3.175 G_L1: 24.051 D_real: 0.001 D_fake: 0.347 \n",
      "(epoch: 87, iters: 238, time: 0.103, data: 0.004) G_GAN: 3.508 G_L1: 14.814 D_real: 0.005 D_fake: 0.382 \n",
      "(epoch: 87, iters: 338, time: 0.106, data: 0.001) G_GAN: 2.486 G_L1: 10.954 D_real: 0.009 D_fake: 0.543 \n",
      "(epoch: 87, iters: 438, time: 0.205, data: 0.001) G_GAN: 2.293 G_L1: 8.648 D_real: 0.175 D_fake: 0.307 \n",
      "(epoch: 87, iters: 538, time: 0.106, data: 0.002) G_GAN: 3.201 G_L1: 10.763 D_real: 0.023 D_fake: 0.406 \n",
      "(epoch: 87, iters: 638, time: 0.104, data: 0.001) G_GAN: 1.883 G_L1: 9.150 D_real: 0.353 D_fake: 0.255 \n",
      "(epoch: 87, iters: 738, time: 0.105, data: 0.001) G_GAN: 4.558 G_L1: 17.731 D_real: 0.057 D_fake: 0.078 \n",
      "End of epoch 87 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 88, iters: 71, time: 0.566, data: 0.001) G_GAN: 1.452 G_L1: 8.116 D_real: 0.374 D_fake: 0.181 \n",
      "(epoch: 88, iters: 171, time: 0.105, data: 0.001) G_GAN: 3.480 G_L1: 12.882 D_real: 0.008 D_fake: 0.868 \n",
      "(epoch: 88, iters: 271, time: 0.105, data: 0.002) G_GAN: 2.403 G_L1: 7.647 D_real: 0.620 D_fake: 1.185 \n",
      "(epoch: 88, iters: 371, time: 0.104, data: 0.001) G_GAN: 2.008 G_L1: 8.371 D_real: 0.071 D_fake: 0.828 \n",
      "(epoch: 88, iters: 471, time: 0.208, data: 0.002) G_GAN: 3.075 G_L1: 11.439 D_real: 0.001 D_fake: 0.302 \n",
      "(epoch: 88, iters: 571, time: 0.105, data: 0.002) G_GAN: 5.212 G_L1: 13.205 D_real: 0.004 D_fake: 1.141 \n",
      "(epoch: 88, iters: 671, time: 0.106, data: 0.001) G_GAN: 3.870 G_L1: 9.072 D_real: 0.000 D_fake: 0.058 \n",
      "End of epoch 88 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 89, iters: 4, time: 0.105, data: 0.001) G_GAN: 3.529 G_L1: 14.686 D_real: 0.004 D_fake: 0.079 \n",
      "(epoch: 89, iters: 104, time: 0.541, data: 0.004) G_GAN: 3.555 G_L1: 16.270 D_real: 0.007 D_fake: 1.090 \n",
      "(epoch: 89, iters: 204, time: 0.104, data: 0.001) G_GAN: 2.403 G_L1: 9.562 D_real: 0.000 D_fake: 0.344 \n",
      "(epoch: 89, iters: 304, time: 0.103, data: 0.001) G_GAN: 3.513 G_L1: 15.101 D_real: 0.039 D_fake: 0.089 \n",
      "(epoch: 89, iters: 404, time: 0.101, data: 0.001) G_GAN: 2.481 G_L1: 9.727 D_real: 0.257 D_fake: 0.162 \n",
      "(epoch: 89, iters: 504, time: 0.542, data: 0.001) G_GAN: 2.305 G_L1: 7.951 D_real: 0.190 D_fake: 0.448 \n",
      "(epoch: 89, iters: 604, time: 0.104, data: 0.002) G_GAN: 4.013 G_L1: 12.654 D_real: 0.009 D_fake: 0.041 \n",
      "(epoch: 89, iters: 704, time: 0.104, data: 0.001) G_GAN: 2.945 G_L1: 13.225 D_real: 0.002 D_fake: 0.256 \n",
      "End of epoch 89 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 90, iters: 37, time: 0.104, data: 0.002) G_GAN: 3.363 G_L1: 10.591 D_real: 0.006 D_fake: 0.098 \n",
      "(epoch: 90, iters: 137, time: 0.529, data: 0.001) G_GAN: 5.171 G_L1: 11.518 D_real: 0.001 D_fake: 0.010 \n",
      "(epoch: 90, iters: 237, time: 0.105, data: 0.002) G_GAN: 2.294 G_L1: 10.536 D_real: 0.061 D_fake: 0.462 \n",
      "(epoch: 90, iters: 337, time: 0.106, data: 0.001) G_GAN: 3.216 G_L1: 14.471 D_real: 0.353 D_fake: 0.032 \n",
      "(epoch: 90, iters: 437, time: 0.105, data: 0.001) G_GAN: 3.034 G_L1: 14.744 D_real: 0.155 D_fake: 0.449 \n",
      "(epoch: 90, iters: 537, time: 0.215, data: 0.001) G_GAN: 1.978 G_L1: 7.766 D_real: 1.048 D_fake: 0.050 \n",
      "(epoch: 90, iters: 637, time: 0.105, data: 0.001) G_GAN: 2.427 G_L1: 19.437 D_real: 0.023 D_fake: 0.215 \n",
      "(epoch: 90, iters: 737, time: 0.105, data: 0.001) G_GAN: 2.657 G_L1: 12.467 D_real: 0.059 D_fake: 0.389 \n",
      "saving the model at the end of epoch 90, iters 69030\n",
      "End of epoch 90 / 200 \t Time Taken: 51 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 91, iters: 70, time: 0.104, data: 0.001) G_GAN: 2.946 G_L1: 9.262 D_real: 0.007 D_fake: 0.192 \n",
      "(epoch: 91, iters: 170, time: 0.606, data: 0.002) G_GAN: 4.290 G_L1: 16.080 D_real: 0.000 D_fake: 0.041 \n",
      "(epoch: 91, iters: 270, time: 0.105, data: 0.002) G_GAN: 1.250 G_L1: 17.302 D_real: 1.006 D_fake: 0.049 \n",
      "(epoch: 91, iters: 370, time: 0.103, data: 0.001) G_GAN: 2.494 G_L1: 11.127 D_real: 0.097 D_fake: 0.255 \n",
      "(epoch: 91, iters: 470, time: 0.105, data: 0.001) G_GAN: 4.745 G_L1: 7.613 D_real: 0.013 D_fake: 0.029 \n",
      "(epoch: 91, iters: 570, time: 0.216, data: 0.001) G_GAN: 4.752 G_L1: 15.805 D_real: 0.107 D_fake: 0.035 \n",
      "(epoch: 91, iters: 670, time: 0.105, data: 0.001) G_GAN: 1.604 G_L1: 8.882 D_real: 0.648 D_fake: 0.207 \n",
      "End of epoch 91 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 92, iters: 3, time: 0.096, data: 0.002) G_GAN: 2.419 G_L1: 6.158 D_real: 0.178 D_fake: 0.179 \n",
      "(epoch: 92, iters: 103, time: 0.103, data: 0.001) G_GAN: 2.068 G_L1: 7.417 D_real: 1.083 D_fake: 0.017 \n",
      "(epoch: 92, iters: 203, time: 0.576, data: 0.001) G_GAN: 2.565 G_L1: 9.111 D_real: 0.072 D_fake: 0.246 \n",
      "saving the latest model (epoch 92, total_iters 70000)\n",
      "(epoch: 92, iters: 303, time: 0.100, data: 0.002) G_GAN: 2.647 G_L1: 7.283 D_real: 1.721 D_fake: 0.731 \n",
      "(epoch: 92, iters: 403, time: 0.105, data: 0.001) G_GAN: 3.815 G_L1: 13.346 D_real: 0.029 D_fake: 0.072 \n",
      "(epoch: 92, iters: 503, time: 0.102, data: 0.001) G_GAN: 4.241 G_L1: 12.148 D_real: 0.026 D_fake: 0.100 \n",
      "(epoch: 92, iters: 603, time: 0.211, data: 0.001) G_GAN: 2.739 G_L1: 16.784 D_real: 0.525 D_fake: 0.049 \n",
      "(epoch: 92, iters: 703, time: 0.104, data: 0.002) G_GAN: 3.756 G_L1: 31.548 D_real: 0.000 D_fake: 0.059 \n",
      "End of epoch 92 / 200 \t Time Taken: 50 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 93, iters: 36, time: 0.106, data: 0.002) G_GAN: 3.041 G_L1: 17.283 D_real: 0.018 D_fake: 0.297 \n",
      "(epoch: 93, iters: 136, time: 0.104, data: 0.001) G_GAN: 4.306 G_L1: 23.104 D_real: 0.020 D_fake: 0.035 \n",
      "(epoch: 93, iters: 236, time: 0.570, data: 0.001) G_GAN: 3.269 G_L1: 9.832 D_real: 0.037 D_fake: 0.594 \n",
      "(epoch: 93, iters: 336, time: 0.102, data: 0.001) G_GAN: 2.035 G_L1: 12.241 D_real: 1.128 D_fake: 0.096 \n",
      "(epoch: 93, iters: 436, time: 0.105, data: 0.001) G_GAN: 0.712 G_L1: 7.958 D_real: 1.769 D_fake: 0.468 \n",
      "(epoch: 93, iters: 536, time: 0.104, data: 0.001) G_GAN: 5.016 G_L1: 9.259 D_real: 0.022 D_fake: 0.011 \n",
      "(epoch: 93, iters: 636, time: 0.225, data: 0.002) G_GAN: 3.083 G_L1: 9.591 D_real: 0.015 D_fake: 0.168 \n",
      "(epoch: 93, iters: 736, time: 0.103, data: 0.002) G_GAN: 2.665 G_L1: 10.094 D_real: 0.996 D_fake: 0.061 \n",
      "End of epoch 93 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 94, iters: 69, time: 0.105, data: 0.001) G_GAN: 2.950 G_L1: 14.947 D_real: 0.002 D_fake: 0.316 \n",
      "(epoch: 94, iters: 169, time: 0.103, data: 0.001) G_GAN: 2.637 G_L1: 9.064 D_real: 0.198 D_fake: 0.082 \n",
      "(epoch: 94, iters: 269, time: 0.582, data: 0.002) G_GAN: 1.931 G_L1: 9.371 D_real: 0.265 D_fake: 0.490 \n",
      "(epoch: 94, iters: 369, time: 0.105, data: 0.002) G_GAN: 2.764 G_L1: 6.083 D_real: 0.037 D_fake: 1.314 \n",
      "(epoch: 94, iters: 469, time: 0.105, data: 0.001) G_GAN: 4.082 G_L1: 9.709 D_real: 0.044 D_fake: 0.093 \n",
      "(epoch: 94, iters: 569, time: 0.103, data: 0.002) G_GAN: 3.878 G_L1: 24.131 D_real: 0.001 D_fake: 0.049 \n",
      "(epoch: 94, iters: 669, time: 0.580, data: 0.002) G_GAN: 1.297 G_L1: 8.775 D_real: 1.147 D_fake: 0.395 \n",
      "End of epoch 94 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 95, iters: 2, time: 0.079, data: 0.001) G_GAN: 4.172 G_L1: 16.238 D_real: 0.126 D_fake: 0.111 \n",
      "(epoch: 95, iters: 102, time: 0.105, data: 0.000) G_GAN: 3.648 G_L1: 17.679 D_real: 0.016 D_fake: 0.074 \n",
      "(epoch: 95, iters: 202, time: 0.104, data: 0.001) G_GAN: 3.107 G_L1: 9.194 D_real: 0.019 D_fake: 0.133 \n",
      "(epoch: 95, iters: 302, time: 0.556, data: 0.001) G_GAN: 1.580 G_L1: 8.422 D_real: 1.753 D_fake: 0.031 \n",
      "(epoch: 95, iters: 402, time: 0.106, data: 0.002) G_GAN: 3.556 G_L1: 18.358 D_real: 0.054 D_fake: 0.158 \n",
      "(epoch: 95, iters: 502, time: 0.104, data: 0.001) G_GAN: 2.726 G_L1: 10.101 D_real: 0.176 D_fake: 0.397 \n",
      "(epoch: 95, iters: 602, time: 0.104, data: 0.001) G_GAN: 3.806 G_L1: 13.394 D_real: 0.005 D_fake: 0.077 \n",
      "(epoch: 95, iters: 702, time: 0.205, data: 0.001) G_GAN: 3.203 G_L1: 11.873 D_real: 0.040 D_fake: 0.113 \n",
      "saving the model at the end of epoch 95, iters 72865\n",
      "End of epoch 95 / 200 \t Time Taken: 51 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 96, iters: 35, time: 0.106, data: 0.001) G_GAN: 3.750 G_L1: 15.694 D_real: 0.010 D_fake: 0.327 \n",
      "(epoch: 96, iters: 135, time: 0.096, data: 0.002) G_GAN: 0.851 G_L1: 6.203 D_real: 1.824 D_fake: 0.135 \n",
      "(epoch: 96, iters: 235, time: 0.103, data: 0.003) G_GAN: 2.547 G_L1: 16.918 D_real: 0.157 D_fake: 0.286 \n",
      "(epoch: 96, iters: 335, time: 0.533, data: 0.001) G_GAN: 0.990 G_L1: 7.645 D_real: 0.910 D_fake: 0.114 \n",
      "(epoch: 96, iters: 435, time: 0.105, data: 0.004) G_GAN: 3.250 G_L1: 13.804 D_real: 0.010 D_fake: 0.110 \n",
      "(epoch: 96, iters: 535, time: 0.103, data: 0.001) G_GAN: 3.106 G_L1: 16.349 D_real: 0.064 D_fake: 0.197 \n",
      "(epoch: 96, iters: 635, time: 0.105, data: 0.001) G_GAN: 2.921 G_L1: 14.143 D_real: 0.237 D_fake: 0.191 \n",
      "(epoch: 96, iters: 735, time: 0.219, data: 0.001) G_GAN: 1.846 G_L1: 5.485 D_real: 0.164 D_fake: 1.288 \n",
      "End of epoch 96 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 97, iters: 68, time: 0.105, data: 0.001) G_GAN: 1.715 G_L1: 5.467 D_real: 2.756 D_fake: 0.031 \n",
      "(epoch: 97, iters: 168, time: 0.106, data: 0.001) G_GAN: 2.388 G_L1: 12.436 D_real: 0.164 D_fake: 0.284 \n",
      "(epoch: 97, iters: 268, time: 0.104, data: 0.002) G_GAN: 3.060 G_L1: 9.223 D_real: 0.051 D_fake: 1.808 \n",
      "(epoch: 97, iters: 368, time: 0.572, data: 0.001) G_GAN: 3.065 G_L1: 8.348 D_real: 0.182 D_fake: 0.080 \n",
      "(epoch: 97, iters: 468, time: 0.104, data: 0.002) G_GAN: 4.629 G_L1: 13.940 D_real: 0.021 D_fake: 0.016 \n",
      "(epoch: 97, iters: 568, time: 0.105, data: 0.001) G_GAN: 3.176 G_L1: 21.487 D_real: 0.005 D_fake: 0.089 \n",
      "(epoch: 97, iters: 668, time: 0.103, data: 0.001) G_GAN: 2.166 G_L1: 19.698 D_real: 0.065 D_fake: 0.465 \n",
      "End of epoch 97 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 98, iters: 1, time: 0.637, data: 0.001) G_GAN: 3.431 G_L1: 9.895 D_real: 0.005 D_fake: 1.235 \n",
      "(epoch: 98, iters: 101, time: 0.104, data: 0.002) G_GAN: 2.047 G_L1: 6.568 D_real: 0.331 D_fake: 0.318 \n",
      "(epoch: 98, iters: 201, time: 0.105, data: 0.001) G_GAN: 3.396 G_L1: 13.327 D_real: 0.072 D_fake: 0.207 \n",
      "(epoch: 98, iters: 301, time: 0.103, data: 0.001) G_GAN: 3.175 G_L1: 9.113 D_real: 0.114 D_fake: 0.209 \n",
      "(epoch: 98, iters: 401, time: 0.221, data: 0.001) G_GAN: 1.729 G_L1: 9.314 D_real: 0.546 D_fake: 0.258 \n",
      "(epoch: 98, iters: 501, time: 0.104, data: 0.001) G_GAN: 1.589 G_L1: 4.890 D_real: 0.473 D_fake: 0.380 \n",
      "(epoch: 98, iters: 601, time: 0.104, data: 0.001) G_GAN: 1.625 G_L1: 15.479 D_real: 1.131 D_fake: 0.073 \n",
      "saving the latest model (epoch 98, total_iters 75000)\n",
      "(epoch: 98, iters: 701, time: 0.103, data: 0.002) G_GAN: 2.650 G_L1: 11.744 D_real: 0.013 D_fake: 0.342 \n",
      "End of epoch 98 / 200 \t Time Taken: 50 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 99, iters: 34, time: 0.628, data: 0.001) G_GAN: 3.569 G_L1: 9.014 D_real: 0.068 D_fake: 0.076 \n",
      "(epoch: 99, iters: 134, time: 0.103, data: 0.002) G_GAN: 2.222 G_L1: 18.859 D_real: 0.010 D_fake: 0.560 \n",
      "(epoch: 99, iters: 234, time: 0.104, data: 0.002) G_GAN: 3.186 G_L1: 10.759 D_real: 0.005 D_fake: 0.198 \n",
      "(epoch: 99, iters: 334, time: 0.104, data: 0.001) G_GAN: 3.115 G_L1: 9.680 D_real: 0.098 D_fake: 0.086 \n",
      "(epoch: 99, iters: 434, time: 0.215, data: 0.002) G_GAN: 2.582 G_L1: 11.843 D_real: 0.025 D_fake: 0.142 \n",
      "(epoch: 99, iters: 534, time: 0.103, data: 0.002) G_GAN: 4.355 G_L1: 12.539 D_real: 0.002 D_fake: 0.031 \n",
      "(epoch: 99, iters: 634, time: 0.105, data: 0.001) G_GAN: 3.086 G_L1: 11.489 D_real: 0.111 D_fake: 0.204 \n",
      "(epoch: 99, iters: 734, time: 0.103, data: 0.002) G_GAN: 3.592 G_L1: 10.361 D_real: 0.047 D_fake: 0.051 \n",
      "End of epoch 99 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0001980\n",
      "(epoch: 100, iters: 67, time: 0.571, data: 0.001) G_GAN: 2.134 G_L1: 7.030 D_real: 0.168 D_fake: 0.177 \n",
      "(epoch: 100, iters: 167, time: 0.103, data: 0.002) G_GAN: 4.059 G_L1: 11.341 D_real: 0.244 D_fake: 0.021 \n",
      "(epoch: 100, iters: 267, time: 0.105, data: 0.001) G_GAN: 1.549 G_L1: 5.248 D_real: 0.468 D_fake: 0.533 \n",
      "(epoch: 100, iters: 367, time: 0.103, data: 0.001) G_GAN: 2.797 G_L1: 15.854 D_real: 0.458 D_fake: 0.097 \n",
      "(epoch: 100, iters: 467, time: 0.225, data: 0.001) G_GAN: 3.591 G_L1: 12.636 D_real: 0.059 D_fake: 0.068 \n",
      "(epoch: 100, iters: 567, time: 0.103, data: 0.002) G_GAN: 1.399 G_L1: 5.737 D_real: 0.452 D_fake: 0.285 \n",
      "(epoch: 100, iters: 667, time: 0.099, data: 0.001) G_GAN: 2.030 G_L1: 9.953 D_real: 0.304 D_fake: 0.319 \n",
      "(epoch: 100, iters: 767, time: 0.103, data: 0.001) G_GAN: 4.053 G_L1: 15.313 D_real: 0.009 D_fake: 1.193 \n",
      "saving the model at the end of epoch 100, iters 76700\n",
      "End of epoch 100 / 200 \t Time Taken: 51 sec\n",
      "learning rate 0.0001980 -> 0.0001960\n",
      "(epoch: 101, iters: 100, time: 0.570, data: 0.239) G_GAN: 3.661 G_L1: 18.786 D_real: 0.000 D_fake: 0.563 \n",
      "(epoch: 101, iters: 200, time: 0.105, data: 0.002) G_GAN: 2.644 G_L1: 16.443 D_real: 0.112 D_fake: 0.149 \n",
      "(epoch: 101, iters: 300, time: 0.104, data: 0.002) G_GAN: 1.638 G_L1: 5.717 D_real: 0.463 D_fake: 0.269 \n",
      "(epoch: 101, iters: 400, time: 0.106, data: 0.001) G_GAN: 3.166 G_L1: 15.235 D_real: 0.008 D_fake: 0.052 \n",
      "(epoch: 101, iters: 500, time: 0.210, data: 0.001) G_GAN: 2.497 G_L1: 12.991 D_real: 0.008 D_fake: 0.207 \n",
      "(epoch: 101, iters: 600, time: 0.104, data: 0.001) G_GAN: 1.686 G_L1: 6.686 D_real: 4.456 D_fake: 0.022 \n",
      "(epoch: 101, iters: 700, time: 0.105, data: 0.002) G_GAN: 3.263 G_L1: 7.625 D_real: 0.210 D_fake: 0.039 \n",
      "End of epoch 101 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0001960 -> 0.0001941\n",
      "(epoch: 102, iters: 33, time: 0.106, data: 0.001) G_GAN: 3.382 G_L1: 15.934 D_real: 0.573 D_fake: 0.025 \n",
      "(epoch: 102, iters: 133, time: 0.555, data: 0.001) G_GAN: 0.691 G_L1: 8.663 D_real: 1.036 D_fake: 0.427 \n",
      "(epoch: 102, iters: 233, time: 0.105, data: 0.002) G_GAN: 2.083 G_L1: 11.096 D_real: 2.367 D_fake: 0.077 \n",
      "(epoch: 102, iters: 333, time: 0.104, data: 0.001) G_GAN: 2.180 G_L1: 9.443 D_real: 0.248 D_fake: 0.438 \n",
      "(epoch: 102, iters: 433, time: 0.104, data: 0.001) G_GAN: 3.648 G_L1: 13.731 D_real: 0.354 D_fake: 0.364 \n",
      "(epoch: 102, iters: 533, time: 0.568, data: 0.001) G_GAN: 1.926 G_L1: 7.189 D_real: 0.119 D_fake: 0.909 \n",
      "(epoch: 102, iters: 633, time: 0.105, data: 0.002) G_GAN: 2.838 G_L1: 17.056 D_real: 0.008 D_fake: 0.140 \n",
      "(epoch: 102, iters: 733, time: 0.104, data: 0.002) G_GAN: 1.098 G_L1: 5.843 D_real: 1.336 D_fake: 0.249 \n",
      "End of epoch 102 / 200 \t Time Taken: 49 sec\n",
      "learning rate 0.0001941 -> 0.0001921\n",
      "(epoch: 103, iters: 66, time: 0.105, data: 0.002) G_GAN: 4.587 G_L1: 9.520 D_real: 0.033 D_fake: 0.015 \n",
      "(epoch: 103, iters: 166, time: 0.632, data: 0.001) G_GAN: 1.652 G_L1: 7.193 D_real: 0.178 D_fake: 0.692 \n"
     ]
    }
   ],
   "source": [
    "!python -m visdom.server\n",
    "!python train.py --dataroot \"/content/drive/My Drive/pytorch-CycleGAN-and-pix2pix-master/datasets/makeup\" --name makeup --model pix2pix --direction BtoA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9UkcaFZiyASl"
   },
   "source": [
    "# Testing\n",
    "\n",
    "-   `python test.py --dataroot ./datasets/facades --direction BtoA --model pix2pix --name facades_pix2pix`\n",
    "\n",
    "Change the `--dataroot`, `--name`, and `--direction` to be consistent with your trained model's configuration and how you want to transform images.\n",
    "\n",
    "> from https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix:\n",
    "> Note that we specified --direction BtoA as Facades dataset's A to B direction is photos to labels.\n",
    "\n",
    "> If you would like to apply a pre-trained model to a collection of input images (rather than image pairs), please use --model test option. See ./scripts/test_single.sh for how to apply a model to Facade label maps (stored in the directory facades/testB).\n",
    "\n",
    "> See a list of currently available models at ./scripts/download_pix2pix_model.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 65468,
     "status": "ok",
     "timestamp": 1605784398890,
     "user": {
      "displayName": "Ege Turan",
      "photoUrl": "",
      "userId": "04174004213434648436"
     },
     "user_tz": -180
    },
    "id": "mey7o6j-0368",
    "outputId": "c247a09d-e345-4b9f-da2a-936161eaec71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 1                             \n",
      "          checkpoints_dir: /content/drive/My Drive/pytorch-CycleGAN-and-pix2pix-master/checkpoints\n",
      "                crop_size: 256                           \n",
      "                 dataroot: /content/drive/My Drive/pytorch-CycleGAN-and-pix2pix-master/datasets/cityscapes/\t[default: None]\n",
      "             dataset_mode: single                        \n",
      "                direction: BtoA                          \t[default: AtoB]\n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 256                           \n",
      "         max_dataset_size: inf                           \n",
      "                    model: test                          \n",
      "             model_suffix:                               \n",
      "               n_layers_D: 3                             \n",
      "                     name: day2night_pretrained          \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_256                      \t[default: resnet_9blocks]\n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                     norm: batch                         \t[default: instance]\n",
      "                 num_test: 50                            \n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: test                          \n",
      "               preprocess: resize_and_crop               \n",
      "              results_dir: ./results/                    \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [SingleDataset] was created\n",
      "initialize network with normal\n",
      "model [TestModel] was created\n",
      "loading the model from /content/drive/My Drive/pytorch-CycleGAN-and-pix2pix-master/checkpoints/day2night_pretrained/latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 54.414 M\n",
      "-----------------------------------------------\n",
      "creating web directory ./results/day2night_pretrained/test_latest\n",
      "processing (0000)-th image... ['/content/drive/My Drive/pytorch-CycleGAN-and-pix2pix-master/datasets/cityscapes/test/1.jpg']\n",
      "processing (0005)-th image... ['/content/drive/My Drive/pytorch-CycleGAN-and-pix2pix-master/datasets/cityscapes/test/103.jpg']\n",
      "processing (0010)-th image... ['/content/drive/My Drive/pytorch-CycleGAN-and-pix2pix-master/datasets/cityscapes/test/108.jpg']\n",
      "processing (0015)-th image... ['/content/drive/My Drive/pytorch-CycleGAN-and-pix2pix-master/datasets/cityscapes/test/112.jpg']\n",
      "processing (0020)-th image... ['/content/drive/My Drive/pytorch-CycleGAN-and-pix2pix-master/datasets/cityscapes/test/117.jpg']\n",
      "processing (0025)-th image... ['/content/drive/My Drive/pytorch-CycleGAN-and-pix2pix-master/datasets/cityscapes/test/121.jpg']\n",
      "processing (0030)-th image... ['/content/drive/My Drive/pytorch-CycleGAN-and-pix2pix-master/datasets/cityscapes/test/126.jpg']\n",
      "processing (0035)-th image... ['/content/drive/My Drive/pytorch-CycleGAN-and-pix2pix-master/datasets/cityscapes/test/130.jpg']\n",
      "processing (0040)-th image... ['/content/drive/My Drive/pytorch-CycleGAN-and-pix2pix-master/datasets/cityscapes/test/135.jpg']\n",
      "processing (0045)-th image... ['/content/drive/My Drive/pytorch-CycleGAN-and-pix2pix-master/datasets/cityscapes/test/14.jpg']\n"
     ]
    }
   ],
   "source": [
    "!python test.py --dataroot \"/content/drive/My Drive/pytorch-CycleGAN-and-pix2pix-master/datasets/cityscapes/\" --name day2night_pretrained --model test --netG unet_256 --direction BtoA --dataset_mode single --norm batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14337,
     "status": "ok",
     "timestamp": 1608136008637,
     "user": {
      "displayName": "Ege Turan",
      "photoUrl": "",
      "userId": "04174004213434648436"
     },
     "user_tz": -180
    },
    "id": "vQvY7EpZHurA",
    "outputId": "3ebb963f-cc90-42ee-ee15-5381d2f2d1eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/pytorch-CycleGAN-and-pix2pix-master\n",
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 1                             \n",
      "          checkpoints_dir: /content/drive/My Drive/pytorch-CycleGAN-and-pix2pix-master/checkpoints\n",
      "                crop_size: 256                           \n",
      "                 dataroot: /content/drive/My Drive/pytorch-CycleGAN-and-pix2pix-master/datasets/summer2winter/\t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: AtoB                          \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 256                           \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: test]\n",
      "               n_layers_D: 3                             \n",
      "                     name: summer2winter_pix2pix         \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_256                      \n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                     norm: batch                         \n",
      "                 num_test: 50                            \n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: test                          \n",
      "               preprocess: resize_and_crop               \n",
      "              results_dir: ./results/4/                  \t[default: ./results/]\n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "loading the model from /content/drive/My Drive/pytorch-CycleGAN-and-pix2pix-master/checkpoints/summer2winter_pix2pix/latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 54.414 M\n",
      "-----------------------------------------------\n",
      "creating web directory ./results/4/summer2winter_pix2pix/test_latest\n",
      "processing (0000)-th image... ['/content/drive/My Drive/pytorch-CycleGAN-and-pix2pix-master/datasets/summer2winter/test/1.png']\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "target_path = \"/content/drive/My Drive/pytorch-CycleGAN-and-pix2pix-master/checkpoints/summer2winter_pix2pix/\"\n",
    "structureD = \"_net_D.pth\"\n",
    "structureG = \"_net_G.pth\"\n",
    "\n",
    "i = 4\n",
    "\n",
    "os.rename(target_path + str(i) + \"_net_D.pth\" , target_path + \"latest_net_D.pth\")\n",
    "os.rename(target_path + str(i) + \"_net_G.pth\" , target_path + \"latest_net_G.pth\")\n",
    "os.mkdir(\"./results/\" + str(i))\n",
    "!python test.py --dataroot \"/content/drive/My Drive/pytorch-CycleGAN-and-pix2pix-master/datasets/summer2winter/\" --direction AtoB --model pix2pix --name summer2winter_pix2pix --results_dir \"./results/4/\"\n",
    "os.rename(target_path + \"latest_net_D.pth\" , target_path + str(i) + \"_net_D.pth\")\n",
    "os.rename(target_path + \"latest_net_G.pth\" , target_path + str(i) + \"_net_G.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1073,
     "status": "ok",
     "timestamp": 1605447554834,
     "user": {
      "displayName": "Ege Turan",
      "photoUrl": "",
      "userId": "04174004213434648436"
     },
     "user_tz": -180
    },
    "id": "78-WV1DcIFfA",
    "outputId": "d4dd862a-8085-4e08-936e-8bdfbc70603d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'caffe'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install caffe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uCsKkEq0yGh0"
   },
   "outputs": [],
   "source": [
    "!python test.py --dataroot \"/content/drive/My Drive/pytorch-CycleGAN-and-pix2pix-master/datasets/cityscapes/\" --direction BtoA --model pix2pix --name cityscapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OzSKIPUByfiN"
   },
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "executionInfo": {
     "elapsed": 1033,
     "status": "error",
     "timestamp": 1603459662247,
     "user": {
      "displayName": "Ege Turan",
      "photoUrl": "",
      "userId": "04174004213434648436"
     },
     "user_tz": -180
    },
    "id": "9Mgg8raPyizq",
    "outputId": "29b831e0-9454-41b5-b7ae-5fa0d1029aa1"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-2ba386e5e9aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./results/facades_label2photo_pretrained/test_latest/images/zoom_background1_fake.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   2059\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mdocstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2060\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2061\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2063\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   1472\u001b[0m             \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_png\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_png\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1474\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_file_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_png\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_png\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36mopen_file_cm\u001b[0;34m(path_or_file, mode, encoding)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mopen_file_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0;34mr\"\"\"Pass through file objects and context-manage `.PathLike`\\s.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m     \u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_filehandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopened\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36mto_filehandle\u001b[0;34m(fname, flag, return_opened, encoding)\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbz2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBZ2File\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'seek'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './results/facades_label2photo_pretrained/test_latest/images/zoom_background1_fake.png'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = plt.imread('./results/facades_label2photo_pretrained/test_latest/images/zoom_background1_fake.png')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 186
    },
    "executionInfo": {
     "elapsed": 804,
     "status": "error",
     "timestamp": 1605784765599,
     "user": {
      "displayName": "Ege Turan",
      "photoUrl": "",
      "userId": "04174004213434648436"
     },
     "user_tz": -180
    },
    "id": "0G3oVH9DyqLQ",
    "outputId": "fdcdfae7-4078-4269-892f-2a2de560ba6b"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-f09cd3c1fd30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./results/day2night_pix2pix/test_latest/images/100_real_A.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "img = plt.imread('./results/day2night_pix2pix/test_latest/images/100_real_A.png')\n",
    "plt.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "pix2pix.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
